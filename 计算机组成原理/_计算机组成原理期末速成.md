# chap1 计算机概述

## 1.1 计算机重要的硬件部件

### 1.1.1 冯诺依曼机的特点

1.   计算机的五大组成部件：运算器，控制器，存储器，输入设备，输出设备
2.   指令和数据以同等地位保存在存储器，可以按照地址寻访
3.   使用二进制表示：
     1.   二进制运算规则简单
     2.   制造两个稳态的物理器件比较容易
     3.   便于用逻辑门电路实现算术运算
4.   指令由操作码和地址码组成
5.   有存储程序
6.   冯诺依曼机以运算器为中心，现代计算机以存储器为中心

【6 这是因为，当年运算器发展缓慢，计算机设计需要围绕运算器ALU，以充分利用其运算能力；现在运算发展快于存储器，所以主要要提高存储器的效率】

### 1.1.2 主存储器

#### 主存储器的组成

1.   存储体：数据在存储体内按照地址储存（核心）
2.   MAR（存储地址寄存器）：MAR位数反映存储单元的个数
3.   MDR（存储数据寄存器）：MDR位数等于存储字长

#### 相关概念

1.   存储元：用来保存二进制信息的电子元件，每个存储元可以存储1bit。
2.   存储单元：每个存储单元存放一串二进制数。
3.   存储字：存储单位中二进制代码的组合
4.   存储字长，二进制代码的位数
5.   1B=1byte=8bit

### 1.1.3 运算器

#### 运算器的组成：

1.   ACC-累加器
2.   MQ-乘商寄存器
3.   X-通用操作数的计算器
4.   ALU-算数逻辑单元

**运算器的主要功能是进行逻辑和算数运算**。

### 1.1.4 控制器

#### 控制器的组成：

1.   CU控制单元：分析指令，给出控制信号
2.   IR指令寄存器：保存当前执行的指令
3.   **PC程序计数器：存放下一条指令地址，有自动加1的功能**

#### 硬件工作过程

初始时指令和数据存入主存，PC程序计数器指向第一条指令，从主存中取出指令放入IR指令寄存器中，PC自动加1，CU控制单元分析指令并发出控制信号来控制其他部件执行指令。

>   [!NOTE]
>
>   控制器和运算器共同组成了中央处理器（CPU）。
>
>   CPU=运算器+控制器+（寄存器）

## 1.2 计算机系统的层次结构

### 1.2.1 层次结构

![image-20250611085537075](D:\universityResource\_课程\计算机组成原理_大一下\pic\计算机系统层次结构.png)

微程序机器$\to$机器语言层（传统机器）$\to$操作系统机器$\to$汇编语言机器$\to$高级语言机器

**计算机硬件可以直接执行的只有机器语言程序**。

## 1.3 计算机的性能指标

### 1.3.1 基本性能指标

1.   字长：一般以Byte为基本单位，最早是16bit，现代一般是32bit或者64bit
2.   主存储量：是主存能储存的最大信息量，等于存储单元数（用M表示，也称字容量）$\times$每个存储单元的二进制位数（用N表示，也称位容量）

>   [!NOTE]
>
>   增加主存容量能减少程序运行期间访问辅存的次数，有利于提高程序的执行速度，也有利于计算机性能的提高。
>
>   1 kilobyte最少需要10根地址线；1 megabyte最少需要20根地址线...

### 1.3.2 与时间有关的性能指标

#### 1 时钟周期

时钟周期是计算机中最基本的、最小的时间单位。

在一个时钟周期内，CPU 仅完成一个最基本的动作。

时钟周期是时钟频率的倒数，也称为节拍周期或 $T$ 周期，随着 CPU 主频的提高，对应的时钟周期将变短。

例如，主频 1GHz（$10^9$ Hz）的 CPU 时钟周期为 1ns。

#### 2 CPI

CPI（Clock Cycles Per Instruction）是指执行每条指令所需要的**平均**时钟周期数。

-   假设程序中包含的总指令条数用 IC 表示，程序执行所需总时钟周期数为 m，机器周期为 T， 频率为 f，则根据上述 CPI 的定义可得：$CPI = \frac{m}{IC}$

-   若能知道某程序中每类指令的使用频率（用 $P_i$ 表示）、每类指令的 CPI（用 $CPI_i$ 表示）、 每类指令的条数（用 $IC_i$ 表示），则程序的 CPI 可表示为：$$CPI=\sum_{i=1}^n(CPI_i \times P_i)=\sum_{i=1}^n(CPI_i \times \frac{IC_i}{IC})$$

#### 3 CPU时间

执行某段程序CPU需要的时间 = 需要的时钟周期数 $\times$ 时钟周期：

$T_{cpu} = m \times T = \frac{m}{f}$

$T_{cpu} = CPI \times IC \times T = \frac{CPI \times IC}{f}$

#### 4 IPC

IPC（Instructions Per Cycle）是指每个时钟周期 CPU 能执行的指令条数，是 CPI 的倒数。由于指令流水线技术以及多核技术的发展，目前 IPC 的值已经可以大于 1，反过来 CPI 的值也可 以小于 1。

#### 5 MIPS

MIPS（Million Instructions Per Second）即每秒百万条指令，更大的单位有 GIPS（Giga  Instructions Per Second）。即，**一秒内可以执行多少百万条指令**。

$MIPS = \frac{IC}{T_{cpu}\times 10^6}=\frac{f}{CPI}=IPC\times f$

#### 6 MFLOPS

MFLOPS（Million Floating-Point Operations Per Second）是指计算机每秒执行浮点运算的次数，而不是 MIPS 所衡量的每秒执行的指令条数。如某系统的运算速度为2MFLOPS，表示该系统的浮点运算速度为每秒 200 万次。更大的单位有 GFLOPS、TFLOPS、PFLOPS。

**MFLOPS 不是计算机实际执行程序的速度，而是计算机在理论上能达到的浮点运算处理速度。**

## 系统互连

算机硬件系统各功能部件还需要有组织地以某种方式连接起来，从而实现数据流信息和 控制流信息在不同部件之间的流动及数据信息的加工处理。在现代计算机中使用较多的就是**总线互连方案**，这种方式实现简单，扩展容易。

 **总线（Bus）是连接两个或多个设备（部件）的公共信息通路。它主要由数据线、地址线和控制线组成**。CPU连接计算机中各主要部件的总线称为系统总线。基于单总线结构的系统互连，如图1.5所示。图1.5 中的所有设备均与总线相连。由于总线是多个设备的公共连接线，因此同一时刻只能允许一个设备向总线发送信息，但可以允许多个设备同时接收来自总线的信息。关于总线的详细内容将在第8章讲述。

![image-20250218183758248](D:\universityResource\_课程\计算机组成原理_大一下\pic\总线互联方案0218.png)

# chap2 数据信息的表示

一般的二进制需要搞定。

### 2.2 一些特殊编码方式

#### 2.2.1 BCD码

【BCD码，Binary-Coded Decimal，8421码用来表示数字】重点理解做加法。在产生进位时，数码是16进制数码，但用来表示十进制数，所以需要+0110补正，这是因为$16-10=6=(0110)_2$。或者直接用十进制做加法，把十进制结果表示成8421码。

#### 2.2.2 ASCII

1.   用七位二进制数表示一个字符，规定最高位为0，凑成八位，共表示128种字符。最高位的0有时候也用于奇偶校验。
2.   在扩展ASCII码中，人们利用利用了第八位，加入了一些欧洲字母和图形字母，如欧元符号等。

| 十进制 |      字符       |
| :----: | :-------------: |
|   32   | blank space ' ' |
|   48   |       '0'       |
|   65   |       'A'       |
|   90   |       'Z'       |
|   97   |       'a'       |
|  122   |       ’z‘       |

#### 2.2.3 字符串

-   最后一位要放置'\0'。

-   注意区分大段和小段。

### 2.3 校验

**码距**：在信息编码中，两个编码对应二进制位不同的个数称为码距，又称海明距离。如：$10101$和$00110$有三位数字不一样，则码距为$3$。

一个有效编码集中，任意两个码字的最小码距称为该**编码集的码距**。校验码的目的就是扩大码距，从而通过编码规则来识别错误代码。码距越大，抗干扰能力、纠错能力越强，数据冗余越大，编码效率越低， 选择码距时应考虑信息出错概率、系统容错率以及硬件开销等因素。增大码距能把一个不具备检错能力的编码变成具有检错能力的编码。校验码就是利用这一原理，在正常编码的基础上，通过增加冗余校验信息来到达增大码距的目的，使其具有检错功能，甚至具有纠错的能力。

| 码距                                     | 检错、纠错能力                             |
| ---------------------------------------- | ------------------------------------------ |
| \($ d \geq e+1 $\)                       | 可检测 \( e \) 个错误                      |
| \($ d \geq 2t+1 $\)                      | 可纠正 \( t \) 个错误                      |
| \($ d \geq e+t+1 $\) 且 \($ e \geq t $\) | 可检测 \( e \) 个错误并纠正 \( t \) 个错误 |

#### 2.3.1 简单奇偶校验

奇偶校验是一种简单的检错编码方法，主要用于检测数据传输或存储过程中是否发生**奇数个比特错误**（1位、3位等）。它通过增加一个**校验位（Parity Bit）**，使得整个数据（包括校验位）中“1”的个数满足既定的奇偶性（奇数或偶数）。

具体地说，**偶校验（Even Parity）**校验位的作用是使数据中“1”的总数为**偶数**。例如`1010`则会编码成`1010 0`。奇校验则相反。

从数字逻辑上，无论奇校验还是偶校验，校验位都可以由各位数数字异或得到，形式上：

$P_{偶}=D_1 \oplus D_2 \oplus D_3 \cdots \oplus D_n$

$P_{奇}=\overline{D_1 \oplus D_2 \oplus D_3 \cdots \oplus D_n}$

#### 2.3.2 交叉奇偶校验

**简单奇偶校验只有一个校验组、一个校验位，故只能提供一位检错信息进行错误检查，无 法纠错。**如果将原始数据信息按某种规律分成若干个校验组，每个数据位至少位于两个以上的校验组，当校验码中的某一位发生错误时，能在多个检错位中被指出，使得偶数位错误也可以被检查出，甚至还可以指出最大可能是哪位出错，从而将其纠正，这就是多重奇偶校验的原理。

**多重奇偶校验最典型的例子是交叉奇偶校验**，其基本原理是将待编码的原始数据信息构造成行列矩阵式结构，同时进行行和列两个方向的奇偶校验。

**交叉奇偶校验能检测出所有 3 位或 3 位以下的错误、奇数位错误、大部分偶数位错误**，能纠正一位错误和部分多位错误，大大降低了误码率，适用于中、低速传输系统和反馈重传系统，被广泛用于通信和某些计算机外部设备中。

![image-20250612061920428](D:\universityResource\_课程\计算机组成原理_大一下\pic\交叉奇偶校验chap2_0612.png)

#### 2.3.3 海明校验

海明校验本质上是一种多重奇偶校验，它是一种既能检错也能纠错的校验码（Error-Correcting Codes，ECC）。海明码通过在数据位中插入多个**校验位（Parity Bits）**，使得每个校验位覆盖特定的数据位。当发生**单比特错误**时，错误的比特位置可以通过校验位的组合唯一确定，从而实现纠错。

| 特性           | 说明                                               |
| :------------- | :------------------------------------------------- |
| **纠错能力**   | 可纠正1位错误                                      |
| **检错能力**   | 可检测2位错误                                      |
| **码距（d）**  | $d=3$（满足 $d \geq 2t+1$，其中 $t=1$）            |
| **校验位数量** | 若数据位为 k，校验位共有r位，满足 $2^r \geq k+r+1$ |

具体编码步骤如下：

1.   确定校验位数量

2.   插入校验位：校验位的位置是 **2 的幂次方**（即 P1,P2,P4,P8,…），其余位置填充数据位。

3. 计算校验位：每个校验位 Pi覆盖所有位置中第 i 位为1的数据位，采用**偶校验**（也可用奇校验，但需统一规则）


|          |   1   |   2   |  3   |   4   |  5   |  6   |  7   |
| :------: | :---: | :---: | :--: | :---: | :--: | :--: | :--: |
| 最终数据 |   0   |   1   |  1   |   0   |  0   |  1   |  1   |
| 原始数据 | $P_1$ | $P_2$ |  1   | $P_3$ |  0   |  1   |  1   |

### 2.4 定点数

#### 2.4.1 定点整数

定点整数为纯整数，约定小数点在所有有效位置之后，第一位是符号位。

#### 2.4.2 定点小数

定点小数是纯小数（绝对值小于1），约定小数点在第一位（符号位）之后。

### 2.5 原、反、补、移码

真值：是用'+'和'-'符号来表示正负的，后面接正常的二进制数。

**原码**是把真值的符号位用0表示正数，用1表示负数。问题在于有两个0，加减法运算也很困难。

**反码**为正数时和原码一样，负数时，把数值位取反。反码可以直接相加，但是最高位有进位时，则需将进位的结果加到最低位，成为循环进位或端回进位。

**补码**的正数表示与原码相同，小于等于0时，符号位变为1，数据位等于真值位逐位取反，末位+1。或者，用扫描法，对真值数据位从右到左顺序扫描，右起第一个 1 及其右边的0保持不变，其余各位求反。

**移码**：将补码的符号位取反就可以得到移码。1. 移码只能用来表示顶点整数（如浮点数的阶码），2. 真值零的移码只有一种，$[0]_{移}=1,000$

### 2.6 浮点数

$N = r^E \times M$，其中E（阶码）和M（尾数）都是有符号的定点数。

#### 2.6.1 规格化浮点数

为了提高运算精度，充分利用尾数的有效位数，避免冗余表示（如$0.0010 \times 2^1$ 和 $0.1000 \times 2^{-2}$其实表示的数值是一个），需要将尾数规格化。我们规定，**尾数的最高数位必须是一个有效值，也就是“1”**，从数学上看，也就是尾数的绝对值在$\frac{1}{2}\to 1$之间，即$\frac{1}{2} \leq |M| \leq 1 $。左规就是尾数是`0001111000`时，左移三位，阶码减去三；右移就是尾数是`1 0010111000`时，右移一位，阶码加上1。

需要注意的是，因为规格化的关系，最小正数应该是`0.10000`的形式。且原码表示和补码表示还有一些不同，具体如下：

>   [!NOTE]
>
>   原码表示：
>
>   - **正数**：
>       - 形式：`0.1××...×`
>       - 最大值：`0.11...1` 
>       - 最小值：`0.100...0` 
>       - 表示范围：$ \frac{1}{2} \leq M \leq (1 - 2^{-n}) $
>   - **负数**：
>       - 形式：`1.1××...×`
>       - 最大值：`1.10...0`
>       - 最小值：`1.11...1` 
>       - 表示范围：$ -(1 - 2^{-n}) \leq M \leq -\frac{1}{2} $
>
>   ---
>
>   补码表示：
>
>   - **正数**：
>     - 形式：`0.1××...×`
>     - 最大值：`0.11...1`  
>     - 最小值：`0.100...0`  
>     - 表示范围：$ \frac{1}{2} \leq M \leq (1 - 2^{-n}) $
>     
>   - **负数**：
>     - 形式：`1.0××...×`
>     - 最大值：`1.01...1`
>     - 最小值：`1.00...0`
>     - 表示范围：$ -1 \leq M \leq -\left(\frac{1}{2} + 2^{-n}\right) $
>
>   **注意：补码负数规格化数尾数部分使用0开头。**比如1.100=$-0.100_2$=$-\frac{1}{2}$不满足$M<-\frac{1}{2}$。可见，规格化不是为了保证开头为1充分利用，还是要从数值关系上考察。

#### 2.6.2 IEEE 754标准

1.   数符：$m_s$都是一位，表示正负
2.   阶码：用移码表示
3.   尾数：用原码表示，不用符号位

| 类型       | 数符 | 阶码位数 | 尾数位数 | 总位数 | 偏置值 (十六进制) | 偏置值 (十进制) |
| ---------- | ---- | -------- | -------- | ------ | ----------------- | --------------- |
| float      | 1    | 8        | 23       | 32     | 7FH               | 127             |
| double     | 1    | 11       | 52       | 64     | 3FFH              | 1023            |
| 临时浮点数 | 1    | 15       | 64       | 80     | 3FFFH             | 16383           |

*临时浮点数用来保存中间运算结果

float浮点数能保存的最大值是：$2^{128}-2^{104}=1.1111 \cdots 1 \times 2^{127}=(2-2^{-23})\times 2^{127}$，



特殊的IEEE 754值：

| 符号位 | 阶码  | 尾数       | 表示                                       |
| ------ | ----- | ---------- | ------------------------------------------ |
| 0/1    | 255   | 1xxxx      | NaN Not a Number                           |
| 0/1    | 255   | 非零 0xxxx | sNaN Signaling NaN                         |
| 0      | 255   | 0          | $$+\infty$$                                |
| 1      | 255   | 0          | $$-\infty$$                                |
| 0/1    | 1~254 | M          | $$(-1)^S \times (1.M) \times 2^{(E-127)}$$ |
| 0/1    | 0     | M (非零)   | $$(-1)^S \times (0.M) \times 2^{(-126)}$$  |
| 0/1    | 0     | 0          | $$+0/-0$$                                  |

# chap3 数据的运算

##  3.1 计算机中的运算基础

考察C语言中的运算，主要有位运算、逻辑运算、位移运算和算数运算。

大部分语言可以直接翻译成汇编语言，其中加减等通常直接翻译成`add`或者`sub`，所有浮点数的运算都会被编译成`fadd`类型指令，即不区分数据类型，但是乘法和除法则会根据操作数符号类型进行不同的转换，对应的汇编指令有`mul` `imul` `div` `idiv`等。

### 3.1.1 位移运算

-   逻辑位移：逻辑左移和右移对空出的位置一律补零
-   循环位移：循环位移会把移出的数字补到缺少的地方
-   算术位移：如果是正数则和逻辑位移一致，负数时要保证符号位不变，同时补码在算数右移时需要补1，反码在左移和右移时都要补1。

### 3.1.2 误差处理

1.   当运算结果超出机器字长时，无条件丢掉超出的位数，这是**截断法**的处理。

2.   如果被舍去的部分非全0（即超出部分不全为0），则将结果的最低位（LSB）强制置1。如果被舍去的部分全为0，则结果的末位保持不变。这是**末位置1法**。类似进一法，但这是一种**不完全对称**的方法。
3.   **舍0入1法**，类似四舍五入，但区分正负数：
     -   对于正数，无论是补码还是原码，若舍去为0，则直接舍去；若为1，则进1
     -   对于负数补码，若舍去部分的最高位为0或者舍去`100...`，直接舍去；若是舍去`1...1...`，则进1。

### 3.1.3 溢出

这里仅考虑模4补码。

这个没啥好说的，双位符号对人类数学来说很直观。

【3.3 中也有溢出】

## 3.2 补码定点数的加减法

我们主要考虑补码的实现。数学基础就是：直接用补码加减得到的补码结果与真实结果一致。如果有小数点，需要先对小数点进行对齐。

## 3.3 溢出检测

【3.1.3 中也有】

*   无符号数：$UOF = Sub \oplus C_{out}$
    *   【转化成文字：加法时进位则溢出；减法时不进位则溢出】
    *   Sub表示是否做减法，这里严格来说不能通过符号位等来判断，只能依靠输入。
    *   sub=0表示正数相加，若$C_{out}=1$则表示有溢出
    *   sub=1表示正数相减（正负数相加），此时$C_{out}=0$表示溢出。对于无符号数相减，会先取补变成有符号数运算（但仍然会用无符号数解释），我们理想成原来的数的最高位都是0，那么变成0+1，若不进位，则表示仍有符号位1，表示出来的是有符号的负数，用无符号数解释的时候会出错，即溢出。（若最高位不是0，则是极端情况，依然符合）

*   有符号数：最高位进位状态$\oplus$次高位进位状态=1，则溢出
    *   因此不溢出的要求是【最高位和次高位同时进位或同时】


*   双符号位：双符号位最高位永远是正确的符号位，因此不同则为溢出。因为成本问题未使用。
    *   $00.X+00.X->01.X$是正上溢出
    *   $11.X+11.X->10.X$是负上溢出

## 3.4 手工补码原码乘法

### 3.4.1 原码的一位乘法

【手工计算的方法对于计算机来说开销太大，我们需要利用右移性质方便在计算机中计算乘法】

1.   由两个乘数的符号位异或得到结果的符号。
2.   数值部分是两个数的绝对值相乘

![P71/Page84](D:\universityResource\_课程\计算机组成原理_大一下\pic\原码一位乘法示意图.png)

### 3.4.2 补码一位乘法

【该方法又称Booth算法，由英国人布斯于 1950 年发明】

1.   所有参与运算的数均以补码表示
2.   一般使用双符号位参与运算，乘数可为单符号位
3.   乘数末位增设附加为$y_{n+1}$，并设置初值为0
4.   按照$(y_n,y_{n+1})$的取值来确定操作数

下面是具体规则和示例：

| $ y_n $（高位） | $y_{n+1} $（低位） | 操作                        |
| --------------- | ------------------ | --------------------------- |
| 0               | 0                  | 部分积右移一位              |
| 0               | 1                  | 部分积加 \([X]\)，右移一位  |
| 1               | 0                  | 部分积加 \([-X]\)，右移一位 |
| 1               | 1                  | 部分积右移一位              |

![image-20250614160112208](D:\universityResource\_课程\计算机组成原理_大一下\pic\补码一位乘法_Booth算法_操作实例.png)

## 3.5 手工原码除法

除法运算与乘法运算的处理思想相似，通常是将n位数的除操作转换成若干次“加、减及移位” 的循环操作来实现。

本节只介绍原码【恢复余数法】和【不恢复余数法】两种除法，补码除法步骤较为复杂，本书不进行介绍，有兴趣的读者请自行查阅相关资料。

### 3.5.1 原码恢复余数法

一般的除法过程需要比较剩余的被除数和除数的大小，而在计算机中这个比较的过程需要做减法。【原码恢复余数法】中余数是指被除数加减后的剩余，恢复则是指在比较过程中，如果发现结果为负数，即商上0时，需要加上除数，使得余数恢复。

**从上例中可以看出恢复余数法的运算过程是一个循环过程：比较→上商（商为 0 时还需要恢复余数）→左移→比较，直到商达到规定的位数为止。一般商的位数与除数的位数相同。**

例题：$[x]_{\text{原}} = 0.1001$，$[y]_{\text{原}} = 0.1011$，求 $[x]_{\text{原}} \div [y]_{\text{原}}$

$[y]_{\text{补}} = 0.1011$，$[-|y|]_{\text{补}} = 1.0101$

![image-20250615085953254](D:\universityResource\_课程\计算机组成原理_大一下\pic\原码恢复余数法P92.png)

### 3.5.2 原码不恢复余数法

**不恢复余数法**是对恢复余数法的改进，主要特点是不够减时不需要恢复余数，而根据余数符号进行不同的运算处理。其运算步数固定，控制简单，有效提高了除法运算速度。其运算过程中分别用加法和减法交替计算余数，所以又称为**加减交替法**。

>   [!NOTE]
>
>   不恢复余数法的运算规则如下：
>
>   1.   当余数与除数同号时，商上 1，余数左移一位，减去除数。
>   2.   当余数与除数异号时，商上 0，余数左移一位，加上除数。
>
>   可以理解为：正就减，负就加，使之一步一步趋近于0。沿着这个逻辑往下走【初始时，如果异号则加[y]，同号则减去[y]】
>
>   【商末位置恒置1】

例：$[x]_{\text{原}} = 0.1001$，$[y]_{\text{原}} = 0.1011$用不恢复余数法求 $[x]_{\text{原}} \div [y]_{\text{原}}$。

 $[[y]]_{\text{补}} = 0.1011$，$[-[y]]_{\text{补}} = 1.0101$。



![image-20250615090601874](D:\universityResource\_课程\计算机组成原理_大一下\pic\原码不恢复余数法.png)

## 3.6 浮点数的运算

浮点数比定点数表示的范围大，有效精度也更高，更适合于工程计算。但它的数据运算处理过程比较复杂，硬件成本高，运算速度也慢一些。浮点数常采用规格化数进行运算。本节将介绍浮点数四则运算法则。【具体表示见2.6】【运算时要辨别表示逻辑，一般的、自定义的、IEEE 754等等标准不同】【只能理解一般的步骤和原则】

### 3.6.1 加减

1.   对阶：小阶向大阶看齐；阶码增加尾数右移
2.   尾数运算：要注意是原码还是补码
3.   规格化：尾数上溢，则右归一位；尾数下溢，左归，归到最大精度
4.   判断溢出：只有阶码溢出时才会溢出，上溢时进入异常处理，下溢时按照机器零处理

### 3.6.2 乘除

按照数学定义做，但是在做除法时先要保证被除数绝对值大于除数。

# chap4 存储系统

## 4.1 存储器概述

### 4.1.1 存储器分类

【需要记住：磁盘是典型的直接存储器，而不是随机访问存储器】

【RAM 和 cache对应的存储器是易失型存储器】

1.   按存储介质分类

     1.   磁存储器

          磁存储器都以磁性材料作为存储介质，利用磁化单元剩磁的不同磁化方向来存储数据0和1。它主要包括**磁芯、磁盘、磁带存储器**等，目前广泛使用的磁盘、磁带中**都包含机械装置**，所以其**体积大、存取速度慢，但磁存储器单位容量成本最低**。

     2.   半导体存储器 

          **用半导体器件组成的存储器称为半导体存储器。**

          目前有两大类：

          	**一种是双极型存储器，主要包括TTL型和ECL型两种**；
			
          	另一种是**金属氧化物半导体存储器**，简称MOS存储器，又可分为静态MOS存储器（SRAM）和动态MOS存储器（DRAM）。

          **半导体存储器体积小，存储速 度快，但单位容量成本相对较高。**

     3.   光存储器

          光存储器**利用介质的光学特性读出数据**，如**CD-ROM、DVD-ROM**均以刻痕的形式将数据存储在盘面上，用激光束照射盘面，靠盘面的不同反射率来读出信息。

          而**磁光盘则利用激光加热辅助磁化的方式写入数据**，根据反射光的偏振方向的不同来读出信息。

          **光盘存储器便于携带，成本低廉，适用于电子出版物的发行。**

2.   按存取方式分类

     1.   随机存储器

          随机存储器（Random Access Memory，RAM）可以按照地址随机读写数据存储单元，且存取访问时间与存储单元的位置无关。

          **早期的磁芯存储器和当前大量使用的半导体存储器都是随机存储器。**

     2.   顺序存储器

          顺序存储器（Sequential Access Memory，SAM）是指存储单元中的内容**只能依地址顺序访问**，**且访问的速度与存储单元的位置有关的存储器**，典型的如**磁带存储器**。

     3.   直接存储器

          直接存储器（Direct Access Memory，DAM）是指不必经过顺序搜索就能在存储器中直接存取信息的存储器，这类存储器**兼有随机存储器和顺序存储器的访问特性**，典型的如**磁盘存储器**。 

          **磁盘由于存在机械寻道和旋转延迟，因此数据访问时间和磁头与目标扇区的距离有关系。**

3.   按信息的可改写性分类

     既能读出又能写入信息的存储器称为**读写存储器**。

     而有些存储器中的内容不允许被改变，只能读出其中的内容，这种存储器称为**只读存储器**（Read Only Memory，ROM），常见的有半导体只读存储器，也有光盘存储器，如CD-ROM、DVD-ROM等。

4.   按信息的可保存性分类

     按照信息保存的时间和条件的不同，存储器分为**易失性存储器和非易失性存储器**。

     易失性存储器是指断电后，所保存的信息会丢失的存储器，常见的如**半导体RAM**。

     非易失性存储器是指断电后，所保存的信息不丢失的存储器，常见的有**半导体ROM、闪存、磁盘、光盘存储器等**。

5.   按功能和存取速度分类

     1.   寄存器存储器
     2.   高速缓冲存储器，又称高速缓存cache，一般采用SRAM构成
     3.   主存储器，主存储器简称主存，是CPU中除寄存器外唯一能直接访问的存储器，用于存放指令和数据。一般由半导体存储器构成，但注意**主存并不是单一的内存，还包括BIOS、硬件端口等**。
     4.   外存储器，简称外存或辅助存储器。目前广泛使用的外存储器包括磁盘、磁带、光盘存储器、磁盘阵列和网络存储 系统等。

---

硬盘驱动器（HDD, Hard Disk Drive）

**原理**：利用磁性存储技术，数据存储在高速旋转的磁盘上，通过磁头读写。

**特点**：
    容量大（可达数十TB）、成本低（单位容量价格低）。
    速度较慢（因机械结构限制，读写速度约100-200 MB/s）。
    易受震动或跌落损坏。
**用途**：大容量数据存储（如服务器、备份系统）。

---

固态硬盘（SSD, Solid State Drive）

**原理**：基于闪存（NAND Flash）技术，无机械部件，通过电子信号读写。
**特点**：
    速度快（读写速度可达数千MB/s，延迟极低）。
    抗震、低功耗、无噪音。
    寿命有限（受闪存擦写次数限制），单位容量成本高于HDD。
**用途**：操作系统安装、高性能应用（如游戏、视频编辑）。

---

混合硬盘（SSHD）
**原理**：结合HDD的大容量和SSD的高速缓存（小容量闪存加速常用数据）。
**特点**：性价比介于HDD和SSD之间，适合需要兼顾容量与性能的场景。

---

### 4.1.2 存储器技术指标

#### 存储容量

存储器可以存储的二进制信息总量称为存储容量。

1.   位表示法。

     以存储器中的存储单元总数与存储字位数的乘积表示，如：

     **1K×4位表示该芯片有1K个单元（1K＝1024），每个存储单元的长度为4个二进制位。**

2.   字节表示法。

     以存储器中的单元总数表示，一个存储单元由8个二进制位组成，称为 一个字节，用B表示，如：

     **128B表示该芯片有128个单元，每个单元都是一个字节，每个字节都由8个二进制位组成**。

#### 存取速度 

1.   **存取时间**：又称为存储器的访问时间，是指启动一次存储器操作（读或写分别对应取与存）到该操作完成所经历的时间，

     注意**读写时间可能不同，DRAM读慢写快、闪存读快写慢。** 

2.   存取周期：连续启动两次访问操作之间的最短时间间隔；对主存而言，存储周期除包 括存取时间外，还包括存储器状态的稳定恢复时间，所以存储周期略大于存取时间。 

3.   存储器带宽：单位时间内存储器所能传输的信息量，常用的单位包括**位/秒**或**字节/ 秒**；带宽是衡量数据传输速率的重要指标，与存取时间的长短和一次传输的数据位的多少有关； 一般而言存取时间越短、数据位宽越大，存储带宽越高。

### 4.1.3 存储系统层次结构

![image-20250519112312099](D:\universityResource\_课程\计算机组成原理_大一下\pic\存储系统的分级结构.png)

### 4.1.4 主存的基本结构

可以看作一个一维数组。指针所指向的其实就是这个一维数组的`index`。

![image-20250519142148178](D:\universityResource\_课程\计算机组成原理_大一下\pic\主存的内部硬件.png)

*   地址译码器接收来自CPU的n位地址信号，经译码、驱动后形成$2^n$根地址译码信号，每一根地址译码信号连接一个存储单元。每给出一个地址，$2^n$个地址译码信号中只有与地址值对应的那个信号才有效，与之连接的存储单元被选中，输出m位数据。 

*   数据寄存器暂存CPU送来的m位数据，或暂存从存储体中读出的m位数据。

*   读写控制电路接收CPU的读写控制信号后产生存储器内部的控制信号，将指定地址的信息从存储体中读出并送到数据寄存器中供CPU使用，或将来自CPU并已存入数据寄存器的信息写入存储体中的指定单元。

### 4.1.5 主存中数据的存放

1.   存储字长与数据字长的概念

     *   **存储字长**：主存的一个存储单元所存储的二进制位数。
     *   **数据字长（简称 字长）**：计算机一次能处理的二进制数的位数。 
     *   **存储字长与数据字长不一定相同，如字长为32位的计算机所采用的存储字长可以是16位、32位或64位。**

2.   地址访问模式

     **存储字长都是字节的整倍数，主存通常按字节进行编址。**

     以32位计算机为例，主存既可以按字节访问，也可以按16位半字访问，还可以按照32位的字进行访问。按照访问存储单元的大小， 主存地址可以分为字节地址、半字地址、字地址。

     **在32位计算机中：字节地址逻辑右移一位即可得到半字地址，右移两位可得到字地址。**

     ![image-20250519143441815](D:\universityResource\_课程\计算机组成原理_大一下\pic\不同主存地址的访问模式.png)

     **不同的地址访问给出的主存地址实际都是字节地址。**

     >   [!TIP]
     >
     >   在汇编指令中，本质上还是给出标准的字节地址，然后通过访问方式，如字节地址访问、半字访问、字访问，选择对应的数据大小。（此时还会结合大端小端法决定顺序）。
     >
     >   注意：
     >
     >   这里的访问方式只能决定大小，比如，不考虑对齐等其他要求的话：
     >
     >   -   **字访问时**：低2位（bit1和bit0）用于选择字中的具体字节。例如：
     >       -   `00`：选择字的第1个字节。
     >       -   `01`：选择字的第2个字节。
     >       -   `10`：选择字的第3个字节。
     >       -   `11`：选择字的第4个字节。
     >   -   **半字访问时**：最低1位（bit0）用于选择半字中的具体字节：
     >       -   `0`：选择半字的第1个字节。
     >       -   `1`：选择半字的第2个字节。
     >   -   **倒数第2位（bit1）**：在半字访问时，如果访问的是字中的半字，bit1用于选择字中的哪个半字：
     >       -   `0`：选择字的低半字（前2字节）。
     >       -   `1`：选择字的高半字（后2字节）。
     >
     >   类似于一个二叉树的寻址方式。
     >
     >   这样设计是为了灵活支持不同大小的数据访问（字节、半字、字），同时确保地址对齐和正确访问内存中的数据。

3.   大端和小端方式

     *   **小端Little-Endian**：当存储器的低字节地址单元中存放的是数据的最低字节

     *   **大端Big-Endian**：当存储器的低字节地址单元中存放的是数据的最高字节

         主流处理器一般都采用小端方式进行数据存放，如Intel x86、IA64处理器、RISC-V处理器。

          有的处理器系统采用了大端方式进行数据存放，如PowerPC处理器。

         还有的处理器同时支持大端和小端方式，如ARM、MIPS处理器。

         除处理器外，外部设备设计、TCIP/IP数据传输、音频和视频文件中都存在数据存放方式的选择问题。

4.   数据的边界对齐

     **目前主流编译器不仅会对数据变量进行边界对齐，还会对复杂的数据结构进行边界对齐。**

## 4.2 半导体存储器

半导体存储器的主要特点是存取速度快、体积小、性能可靠，已成为实现主存的首选器件。 半导体存储器通常分为随机存储器和只读存储器。



**存储单元**是存储器中的最小存储单位，也称为存储元，其作用是存储一位二进制信息。

**存储单元的基本功能**：

*   具有两种稳定状态。 
*   两种稳定状态经外部信号控制可以相互转换。 
*   经控制后能读出其中的信息。 
*   无外部原因，其中的信息能长期保存。（在系统运行和供电时能长期保存）

### 4.2.1 静态MOS存储器SRAM

以静态MOS存储元为基本单元组成的存储器称为静态MOS存储器（SRAM）。

#### 静态MOS存储单元

静态存储单元的结构有多种，一种典型的**6管SRAM存储单元电路**如图4.6所示。

其中 T1 、T2 为工作管；T3 、T4 为负载管（功耗管）；T5 、T6 、T7 、T8 为门控管，相当于控制开关，控制存储单元数据信息与外界的连通或隔离。**静态存储单元由T1 、T2 组成的双稳态触发器存储一位二进制信息。**

![image-20250519150315595](D:\universityResource\_课程\计算机组成原理_大一下\6管SRAM存储单元.png)

关于存储单元的详细介绍见书101页。一般会封装成下图的样子：

![image-20250519150908617](D:\universityResource\_课程\计算机组成原理_大一下\pic\6管SRAM封装.png)

#### 存储单元扩展

可以从一个存储单元拓展成存储矩阵，可以随机访问其中任何一位数据。

加上行缓冲器，就可以一次访问一整行的内容，但无法访问一整列的内容。

下面是扩展的4K大小的存储矩阵：

![image-20250519151510549](D:\universityResource\_课程\计算机组成原理_大一下\pic\4K存储矩阵.png)

一次读出一行：

![image-20250519151706592](C:\Users\szl-d\AppData\Roaming\Typora\typora-user-images\4K存储矩阵_行通选.png)



**译码器Decoder**，我更喜欢称之为解码器，是组合逻辑电路，其功能是将n位二进制信号输入翻译成 $2^n$ 个输出信号，每个输出信号都是n位输入的最小项，所以**译码器也称为最小项发生器**。比如，我输入 6 位二进制数 `001001`（即 $A_5A_4A_3A_2A_1A_0=001001$），其对应的十进制是`9`，那么输出序列$Y_9 = 1 ; Y_{else}=0  其中，{else} \in (0 \to 8)\cup (10 \to 63)$ 。



假设地址位宽为 n 位，对于一维行扩展，只需要一个 n 路输入译码器即可，这种结构也称为**单译码结构**。

其译码输出信号为$2^n$根，假设$n＝16$，则$2^n$＝65536。

**随着n值变大，译码器电路的开销不容忽视，另外译码输出过多也会占用较多的晶圆面积，其生产制造也会存在困难**

而对于二维行列扩展，需在行列两个方向各设置一个n/2＝8路输入译码器（行、列地址数目也可以不一样），这种结构称为**双译码结构**。其译码输出信号为$2×2^{\frac{n}{2}}＝512%$根，存储容量为$2^{\frac{n}{2}} \times 2^{\frac{n}{2}} ＝ 2^n$，和单译码结构一样，但输出信号少很多，译码电路成本也会大大降低.

因此**在大容量存储器中普遍采用双译码结构**。单译码和双译码结构具体原理如图4.9所示。

![image-20250519154229260](D:\universityResource\_课程\计算机组成原理_大一下\pic\单译码和双译码结构.png)

通过二维存储扩展，很容易构建大容量的SRAM，但这样的存储器给出地址后，同一时刻只有一个存储单元被选中，一次只能访问一位数据，而实际存储器均是以字节为基本单位的， 如何扩展存储器的字长呢？其实方法很简单，只需要将**多个一位存储体的地址线并联在一起工作即可同时得到多位的数据**，这种方法称为**字长扩展**。

#### 静态 MOS 存储器的结构

![image-20250519160238186](D:\universityResource\_课程\计算机组成原理_大一下\pic\静态MOS存储器的结构.png)

#### 静态MOS存储器芯片实例

Intel 2114 是 Intel 公司推出的一款1K×4位的SRAM芯片，图4.11（a）所示为该芯片的封装引脚示意图，该芯片包括1024个字，字长4位；除电源和接地引脚外，该芯片还包括地址输 入引脚10个，数据双向输入输出引脚4个，另外还包括片选信号$\overline{CS}$ 和写使能信号$\overline{WE}$ 两个引脚。

![image-20250519160508603](D:\universityResource\_课程\计算机组成原理_大一下\pic\Intel_2114.png)

**X向驱动器需求比Y向更高， 所以通常设计成列地址少，行地址多。**

输入数据控制，写周期中：

*   地址有效后必须等待一段时间间隔，写信号WE才能有效，否则可能导致写出错
*   写信号WE无效后，还要经过一段时间间隔才能改变地址，否则也容易导致写出错
*   教材P105（读写周期时序，有兴趣可以看看，不做要求）

#### SRAM读写时序

存储器具有自己的读写周期特性，只有按照存储器的读写周期去访问存储器才能保证读写操作的正确性。

见书105页。

### 4.2.2 动态MOS存储器DRAM

存储体以动态MOS存储元为基本单元组成的存储器称为动态MOS存储器（DRAM）。

SRAM需要6个MOS管才能存储1位数据，存储密度较低；另外即使存储单元不进行读写，功耗管和导通的工作管之间也有电流存在，其功耗较大。为了去掉MOS管中的功耗管，**引入了存储电容暂存电荷的方式来保存数据**。由此出现了4管DRAM存储单元，包含4个MOS管和2个存储电容；还有3MOS管和1个存储电容的存储单元，如Intel公司第一块DRAM芯片1103。**目前在内存中较为常见的结构是单管动态MOS存储单元。**

>   [!IMPORTANT]
>
>   DRAM和SRAM的比较：
>
>   -   SRAM：
>       -   **使用MOS管多，存储密度低，功耗大**
>       -   **存在功耗管，数据不会丢失，无需刷新操作**
>       -   **读写速度更快**
>       -   **价格更贵，常用于构造高速缓存Cache**
>   -   DRAM：
>       -   **只需要一个MOS管和一个存储电容**，**存储密度高**，功耗小
>       -   电容存储电荷容易泄露，需要刷新
>       -   **读出操作属于破坏操作，需要进行数据恢复**
>       -   **电容充放电时间长导致读写速度更慢**
>       -   **价格便宜，适合构造大容量的半导体存储器**，如**主存**

#### 单管动态MOS存储单元

单管动态MOS存储单元仅仅**使用一个MOS管和一个电容构成存储单元**，这也是目前内存中基本存储单元的结构，基本存储单元如图4.13中蓝色圆圈内部的电路所示。

![image-20250519164503930](D:\universityResource\_课程\计算机组成原理_大一下\pic\单管DRAM内部电路.png)

**单管动态MOS存储单元利用存储电容C是否带电荷来表示数据，有电荷表示数据“1”， 无电荷表示数据“0”。**

#### DRAM特点

1.   **存储电容的容量比寄生电容要小一个量级**，所以执行**读操作时二者进行电荷重分配产生**的**电流十分微弱**，需要用**非常灵敏的差分放大器**进行检测。
2.   读操作可能会引起电荷减少，从而破坏原有数据，为避免数据丢失，读出后会将数据重新写入，该过程称为**数据恢复**。
3.   数据恢复以及读出信号放大的逻辑由再生放大电路实现，**通常每组列线上都有一个共享的再生放大电路**，该电路为该列上所有存储单元所共享。
4.   电容上的电荷会逐渐泄漏，数据只能保存较短的时间。为避免数据丢失，必须定期采用**类似读操作**的方式对存储单元补充电荷，这个过程称为刷新，这也是动态RAM得名的原因。
5.   图中也包含两条对称的位线，每一列都包含一组共享的预充电路和读出放大检测电路。读出放大检测电路由4个MOS管构成，是一个跷跷板电路。**当位线上的电压有微弱差异时，跷跷板电路的平衡被打破，电压略高一侧会变成稳定的高电平逻辑“1”，另一侧则变成稳定的低电平逻辑“0”。**

#### DRAM的读写操作流程

与SRAM不同，**DRAM的地址线采用分时复用技术**。在访问存储单元时，**不能同时给出行地址和列地址**，而是需要先通过地址引脚发送行地址（并锁存到行地址缓冲器），再通过**同一组**地址引脚发送列地址（锁存到列地址缓冲器）。

**这种设计只需一套地址引脚，大幅减少了芯片封装引脚数量，但需要额外的行选通（RAS）和列选通（CAS）控制信号配合时序操作。**



-   DRAM的读操作流程：

1.   预充操作 Precharge：给出预充信号，由预充电路将位线$D$和 $\overline{D}$预充到$V_{CC} / 2$的电压后，此时位线上的寄生电容保持$V_{CC} / 2$ 的电压；**预充的目的是加速读取的过程，类似将跷跷板支撑到一定的高度， 方便跷跷板一上一下**。

2.   访问操作 Access：

     行选通，T1管导通
     存储电容C和位线D的寄生电容电荷重分配：

     	存储电容有电荷：存储数据“1”，电容向位线D放电，D上的电压将略高于$Vcc/2$ 
		
     	 存储电容无电荷：存储数据“0”，位线D向电容充电， D上的电压将略低于$Vcc/2$ 

     引起两个位线D 和$\overline{𝐷}$上的电压微弱差异。

3.   信号检测 Sense

4.   数据恢复 Restore

5.   数据输出 Output

写操作流程也需要经历与读操作前 4 步一样的流程，这样写入操作也可以实现和读操作一样的行刷新功能，数据恢复后只需给出列选通信号，将写入数据由 D 和 $\overline{D}$ 线送入即可。写入“1”时，位线上的高电平使得存储电容充电；写入“0”时，位线 D 上的低电平使得存储电容放电；完成充、放电后，撤除行选通信号，使得 T$_1$ 管截止，完成写入操作。

**感觉这一段学懂太难了，交给题目拟合吧**

**在书的107页，老师ppt的42页**

#### DRAM存储的刷新

-   **刷新**：定期补充电荷，避免电容的电荷泄露引起的信息丢失。

-   **刷新周期**: 存储器两次完整刷新之间的时间间隔
    -   信息存储到泄漏之间必须完成刷新，称为**最大刷新周期**
    -   不同材料和生产工艺，最大刷新周期不同，常见的有2ms、4ms、8ms
    -   **理论上减少存储矩阵的行数，增加列数，可以减少刷新周期**，因为是按行刷新
-   按行刷新
    -   **刷新地址由刷新地址计数器产生，而不是由CPU发出**，刷新地址计数器的位数与动态存储芯片内部的行结构有关，通常刷新操作由内存控制器负责。如果某动态存储芯片内部有256行，则刷新地址计数器至少为8位，在每个刷新周期内，该计数器的值从00000000到11111111循环一次。
-   读操作虽然具有刷新功能，但读操作与刷新操作又有所不同，**刷新操作只需要给出行地址**，而不需要给出列地址。
-   刷新时DRAM不能响应CPU的访问，所以CPU访问内存和内存控制器刷新操作存在内存**争用问题**，常见的解决方式有**集中刷新、分散刷新、异步刷新**3种。

##### Burst Refresh

-   **原理**：在固定的时间间隔内，集中安排一段时间对所有存储单元进行连续刷新。在此期间，存储器暂停所有读写操作。
-   **特点**：
    -   **优点**：刷新操作集中完成，刷新期间外存储器可以全速工作，读写效率高。
    -   **缺点**：刷新期间会阻塞所有读写请求（称为“死时间”），可能导致系统延迟。
-   **适用场景**：对连续读写性能要求高、能容忍短暂阻塞的场景。
-   假设DRAM有8192行，刷新周期为64ms，集中刷新时可能在2ms内连续刷新所有行，期间存储器不可用。

##### Distributed Refresh

-   **原理**：将刷新操作分散到整个刷新周期内，每次刷新一行或几行，而不是集中完成。通常在每个正常的读写周期后插入一个刷新周期。
-   **特点**：
    -   **优点**：避免了集中刷新的“死时间”，系统响应更平滑。
    -   **缺点**：由于频繁插入刷新操作，存储器的有效带宽会降低。
-   **适用场景**：对实时性要求高、不能接受长时间阻塞的系统。
-   在64ms的刷新周期内，每隔7.8μs（64ms/8192行）自动刷新一行，与读写操作交替进行。

##### Asynchronous Refresh

-   **原理**：刷新操作由外部控制器异步触发，与存储器的正常读写操作独立。**刷新请求可以优先级较低，在系统空闲时执行。**
-   **特点**：
    -   **优点**：灵活性高，可动态调整刷新时机，减少对性能的影响。
    -   **缺点**：需要复杂的控制器协调刷新和读写操作。
-   **适用场景**：低功耗设备或需要动态优化性能的场景（如移动设备）。
-   **CPU检测到总线空闲时，触发刷新操作；若系统繁忙，则延迟刷新。**

#### DRAM实例

动态MOS存储器芯片与静态MOS存储器芯片的结构**大致相同**。但由于动态MOS存储器芯片**集成度高**，而且要进行**刷新**操作，因此它的外围电路**相对要复杂**一些。

2116是一种典型的DRAM芯片。图4.15所示为动态MOS存储器芯片2116的逻辑符号和内部结构。

![image-20250521085224217](D:\universityResource\_课程\计算机组成原理_大一下\pic\DRAM实例2116芯片.png)

2116 表示 16K × 1 位存储芯片，其采用地址复用技术，分别由行地址选通信号 $ \overline{RAS} $ 和列地址选通信号$ \overline{CAS}$ 先后将 7 位地址 A0 ∼ A6 分别锁存到行地址锁存器与列地址锁存器中。存储矩阵为 128 × 128 结构；7 条行地址线也可作为刷新地址，刷新时用于地址计数，逐行刷新。

行、列地址译码后均产生 128 条选择线。选中某行时，该行的 128 个存储元都被选通到放大再生电路中，在那里每个存储单元会进行预充、访问、检测、恢复的过程。而列译码器中只选通 128 个放大器中的一个，将读出的信息送入输出缓冲器中。

从前面的分析可看出，DRAM 的结构大体与 SRAM 存储芯片相似，二者的不同点如下：
（1）**地址线一般采用复用技术，即 CPU 分时传送行、列地址，并分别由行选通信号 RAS 和列选通信号 CAS 选通。**
（2）**DRAM 无片选信号，通常可由 RAS 和 CAS 选通信号代替。**
（3）数据输入$ D_{IN} $和数据输出 $ D_{OUT}$**分开且可锁存**。

## 4.3 主存的组织和CPU的连接

单片存储芯片的存储容量有限，要获得一个大容量的存储器，通常需要将多片存储芯片按照一定的方式组织来实现并与 CPU 连接，这就是**存储器的组织**。

在存储器组织过程中，要实现存储芯片与 CPU 地址线、数据线和控制线的**连接**，需要注意以下几点：

1.   连接的地址线的数量与 CPU 要访问的主存容量有关。
2.   连接的数据线的数量与计算机字长有关。
3.   SRAM 芯片的控制线包括片选信号和读写控制线。
4.   ROM 芯片的控制线只有片选信号线。
5.   DRAM 没有片选控制线，进行容量扩展时，可以利用$\overline{RAS}$和$\overline{CAS}$控制芯片的选择。

![image-20250621105952374](D:\universityResource\_课程\计算机组成原理_大一下\pic\主存储器与CPU的连接.png)



【这里对应三个考点：字扩展+位扩展+字位同时扩展】

---

接下来的部分对应一个问题：如何解决CPU与存储器的速度无法匹配的问题？

解决之道：

1.   采用高速器件提高速度；
2.   并行：在每个存储周期中存取多个字。
     1.   采用双端口存储器
     2.   将主存划分为多个模块，多模块并行
3.   增加高速缓冲存储器Cache

---

## 4.4 并行主存系统

目前，主存的存取速度已经成为提升计算机系统性能的瓶颈，除可以通过选择高速元件来提高存储器访问速度外，也可以通过存储体的并行工作来提高存储器的访问速度，缓解 CPU 与主存速度不匹配的问题。本节主要研究如何通过发掘存储系统的并行性来提高其存取速度。

### 4.4.1 双端口存储器

双端口存储器是指同一个存储器具有两组相互独立的端口，每个端口均有各自独立的数据端口、地址端口、读写控制端口、片选端口等，每个端口可独立地进行读写操作。

![image-20250621120750821](D:\universityResource\_课程\计算机组成原理_大一下\pic\双端口存储器.png)

1.   并行读写：当左右两个端口的地址不同时，两个端口使用各自的地址线、数据线和控制线对存储器中同的存储单元同时进行读写操作，二者不发生冲突。
2.   冲突处理：当两个端口的访问地址相同时，便会发生读写冲突。为解决冲突，每个端口各设置了一个标志BUSY。当冲突发生时，由判断逻辑决定哪个端口优先进行读写操作，而将另一个端口BUSY置 0（BUSY变为低电平）以延迟其对存储器的访问。优先端口读写操作完成，被延迟端口的BUSY标志复位（变为高电平）后，便可进行被延迟的操作。
3.   **由于冲突访问不可避免，因此双端口存储器的速度不可能提高两倍。**

### 4.4.2 单体多字存储器

**单体多字存储器的构造与存储器位扩展方式完全相同**（参考图 4.24），该方式中多个存储模块共享地址总线，按同一地址并行访问不同存储模块的同一单元，从而实现在同一个存储周期内访问多个存储字，如果 m 个存储模块并发工作，则主存带宽可提升 m 倍。（**性能线性增长**，总线位宽变化）

即，使用一个地址可以访问多个模块，从而实现多个储存字的并行访问。

例如，存储字长是64位，而机器字长是32位。现在给出一个存储地址，那么会访问到一个64位的数据，然后再对他的高32位或者低32位做修改。这样，在访问数组时，访问效率会提高两倍。

![image-20250621122205616](D:\universityResource\_课程\计算机组成原理_大一下\pic\单体多字存储器概念图.png)

目前在计算机中常见的多通道内存技术就是采用的单体多字技术，常见的有双通道、三通道、四通道技术。

-   **单体多字存储器**（也称 **联动模式**）：共享地址总线、片选信号；两个内存的容量、频率、时序完全一样

-   **多体多字存储器**（也称 **非联动模式**）：独立的片选信号、地址总线、读写控制线、数据总线；

    频率相同，**容量和时序不需一致**

![image-20250621122432929](D:\universityResource\_课程\计算机组成原理_大一下\pic\多通道内存技术.png)



![image-20250621122535296](D:\universityResource\_课程\计算机组成原理_大一下\pic\两种通道模式.png)

### 4.4.3 多体交叉存储器

也叫 **多体单字存储器** 。多体交叉存储器也由多个存储模块构成，这些模块的容量和存取速度相同。根据对多个模块编址方式的不同，其组织方式又可分为高位多体交叉和低位多体交叉两种。

【对于 n 体交叉存储器，通常采用低位交叉编址】

>   [!NOTE]
>
>   -   多模块顺序存储器：高位多体交叉，多模块串行，扩充容量，方便故障隔离，**性能无提升**。
>   -   多模块交叉存储器：低位多体交叉，多模块流水并行，扩充容量，提升性能

![image-20250621122918078](D:\universityResource\_课程\计算机组成原理_大一下\pic\多体交叉存储器.png)

#### 一、高位交叉方式

**高位多体交叉**方式的主要目的是扩充存储器的容量，与存储器字扩展完全相同（参考图 4.25），即用高位地址译码产生片选信号，选择不同的存储模块；而低位地址直接选择一个存储模块内的不同存储单元。高位交叉方式中不同存储模块对应不同的地址区间，将地址顺序分配给一个模块后，按顺序为下一个模块分配地址。因此，**高位多体交叉又称为顺序编址模式**。

由于程序具有局部性和连续性的特点，采用高位交叉组织存储器时，同一个存储体中的地址单元是连续的，这样程序执行过程中的指令和数据基本分布在同一个存储体中，**往往会导致一个存储体访问频繁**，而其他存储体基本处于空闲状态，无法实现多个存储体的并行工作。 计算机中的内存插槽插入一个或多个内存条都可以正常工作，这种方便的扩充容量的方式就是典型的顺序编址模式。

#### 二、低位交叉方式

其地址结构如图 4.29（b）所示，这种编址方式又称为**交叉编址模式**，从图中可以看出，低位交叉方式下的数据组织具有特点 : <u>1. 相邻的地址处在不同存储体内。2. 同一存储体中的地址不相邻 3.  低位片选，多模块可并行工作(连续访问相邻数据时)。</u>

-   并行工作时，按照流水线方式轮流存取（数据总线宽度为单字长），提高存储带宽。

#### 低位交叉存储器按流水方式存取

流水线的意义在于：正常选取存储单元，但是在数据传输时，正好错开总线传输时间。

>   [!NOTE]
>
>   - 实现流水方式存取需满足条件：
>     - $T = m\tau$
>     - 各个存储体错开$\tau$时间**分时启动读写操作**
>     - 各存储体中的数据分时传送
>
>   - 经过一个存储周期$T$之后，每隔$\tau$时间延迟可传送一个新的数据
>
>   - 连续读取$n$个字的时间
>     - 交叉访问方式$t_1 = T + (n-1) \tau$
>     - 顺序访问方式$t_2 = nT$
>     - $t_1 < t_2$
>
>     - $$\lim_{n \to \infty} \frac{t_2}{t_1} = \lim_{n \to \infty} \frac{nT}{T + (n-1)\tau} = \frac{T}{\tau} = m$$

>   [!NOTE]
>
>   【题目】设计计算机字长64位，存储器容量为128MW，采用模数m为8的存储器交叉方式进行组织，存储周期$T=200$ns，数据总线宽度为64位，总线传送周期$\tau=25$ns，若连续读取10个字，分别计算顺序访问方式和交叉访问方式下存储器的带宽。
>
>   
>
>   【解】顺序和交叉方式连续读出10个字的信息总量都是：$q=64 \times 10 = 640$bits  
>   $m\tau = 8 \times 25$ns = 200ns = T，可以实现流水方式存取
>
>   顺序方式下，连续读出10个字所需要的时间：$T_1 = 10T = 2000$ns  
>   存储器带宽：$W_1 = q/T_1 = 640 \text{ bits}/2000 \text{ns} = 3.2 \times 10^8 \text{bit/s} = 320 \text{Mb/s}$
>
>   交叉方式下，连续读出10个字所需要的时间：$T_2 = T + (10-1)\tau = 425$ns  
>   存储器带宽：$W_2 = q/T_2 = 640 \text{ bits}/425 \text{ns} \approx 1.5 \times 10^9 \text{bit/s} = 1.5 \text{Gb/s}$

## 4.5 Cache 高速缓冲存储器

【脏数据】

早期U盘写速度慢，部分内存空间为U盘作写缓冲，数据写入内存即报告写操作完成

-   可有效提升写性能，改善用户等待体验
-   导致数据不一致性，产生脏数据
    -   脏数据（Dirty Data）：新写入的数据与主存中的原始数据不一致，这部分新数据称为脏数据。
    -   系统将定时或被迫将脏数据迁移到U盘，不安全的拔盘可能丢失脏数据

### 4.5.3 cache 的基本概念

- 命中 hit: CPU访问数据在cache中（上层存储器）
- 缺失 miss: CPU访问数据不在cache中
- **块 block**: cache与主存交换最小单位
  - 利用空间局部性实现预读
  - 块大小多少合适？？？
- **Cache中的行/槽 Line/Slot 包含**：
  - 一个数据块副本
  - 有效位、查找标记、脏标志位、置换标记（淘汰计数）、
- Cold Cache、Warm Cache:
  - 替换算法根据置换标记选择换出的Cache行
- 命中率 （hit rate）
  - 主存访问中cache命中比例
- 缺失率 （miss rate）
  - $1 - 命中率$
- 命中访问时间：（hit time）
  - 数据命中情况下，访问数据所需的时间：<u>数据查找时间、cache访问时间、总线传输时间</u>
- 缺失损失 （miss penalty）
  - 数据缺失情况下，访问数据所需的时间：<u>数据查找时间、主存块调入cache，数据传输到处理器的时间</u>
  - 远大于命中时间
- 访问效率$e=\frac{t_c}{t_a}=\frac{t_c}{ht_c+(1-h)t_m}$
  - 一般以5-10为宜，约接近1访问效率越高


### 4.5.4 cache读写流程与关键技术

#### cache 读操作流程

![image-20250621150659944](D:\universityResource\_课程\计算机组成原理_大一下\pic\cache读操作流程.png)

#### cache 写操作流程

![image-20250621150831649](C:\Users\szl-d\AppData\Roaming\Typora\typora-user-images\cache写操作流程.png)

>   [!NOTE]
>
>   cache关键技术：
>
>   1.   数据查找 Data Identification：如何判断数据在cache中
>   2.   地址映射 Address Mapping：主存数据如何放置到cache行/槽中
>   3.   替换策略 Placement Policy：cache满后如何处理
>   4.   写入策略 Write Policy ：如何保证cache与memory的一致性

### 4.5.5 相联存储器 CAM

相联存储器（Content Addressable Memory，CAM）是一种按内容进行访问的存储器，用于存放查找表，其内部存储的基本数据单元是键值对。

CAM 的输入不是地址，而是检索关键字 key，输出则是该关键字对应的 value 值。【原理如图所示】

![image-20250621162444730](D:\universityResource\_课程\计算机组成原理_大一下\pic\相联存储器基本原理.png)

-   图中包括4个键值对，每行都有一个键值对，其中一个有效位用于表示当前键值对是否有效（为 1 时有效，为 0 时无效）。

-   用输入的Key（在图片最上方）和左侧所有的$valid \& key$做**并发逻辑运算**，**有效位为1且比较结果相同则输出为1**。
-   这样，便可以通过三态门**输出对应的Value值**；同时，通过一个**或运算**，便可以得到$hit$值。

**CAM 中的每个存储单元都对应一个独立的比较器，硬件成本高昂，所以通常容量不会太大。**

**在计算机系统中，CAM 通常用于 cache 的快速查找，也可用于在虚拟存储器中存放段表、页表和 TLB 表。**

### 4.5.6 地址映射

地址映射是**指将主存地址空间映射到 cache 的地址空间**，即把存放在主存中的程序或数据块载入 cache 块的规则。

地址映射主要有以下 3 种方法：

1.   **全相联（Full Associative Mapping）**：各主存块都可以映射到 cache 的任意数据块。
2.   **直接相联（Direct Mapping）**：各主存块只能映射到 cache 中的固定块。
3.   **组相联（Set Associative Mapping）**：各主存块只能映射到 cache 固定组中的任意块。

#### 4.5.6.1 全相联映射

-   全相联映射方式下，主存中的每一个数据块都可以放置到 cache 的任意一个数据块中，是一对多的映射关系。
-   新的主存数据块可以载入 cache 中任何一个空位置，只有 cache 满时才需要进行数据块置换。
-   **全相联映射时 cache 利用率最高，但查找成本较高，淘汰算法复杂**，需要 CAM 提供快速的查找功能。

由于主存块可以放置在 cache 的任意块中，为了方便后续查找，<u>主存数据块载入时还需要记录若干的标记标志信息</u>，主要包括<u>有效位、主存块地址标记、脏数据标志位、淘汰计数</u>等信息。通常将一个 cache 数据块和相关的标记标志信息一起称为一个 cache 行 / 槽（Line/Slot），因此 cache 有多少个数据块就对应有多少个 cache 行。

主存地址划分为**主存块地址（tag）**和**块内偏移（offset）**两部分，两部分字段长度分别为$s$、$w$。由图可知，cache块大小 = $2^w$字节，cache副本缓冲区容量 = $n \times 2^w$字节，主存容量 = $2^{s+w}$字节，不考虑脏数据位和淘汰计数，cache的实际容量为$n \times (1 + s + 8 \times 2^w)$位。

数据查找时直接将主存块地址和所有cache行中的标记字段主存块地址进行并发比较，如果读命中，则输出对应cache行数据块副本中块内地址offset处的数据；如果写命中，则需要写入数据，同时将脏数据标志位置为1。

![image-20250621202636588](C:\Users\szl-d\AppData\Roaming\Typora\typora-user-images\全相联映射.png)

#### 4.5.6.2 直接相连映射

![image-20250621202737739](D:\universityResource\_课程\计算机组成原理_大一下\pic\直接相连映射.png)

直接相联映射的硬件开销：只需一个比较器，无需使用相联存储器

cache行包括：标记位=区地址；数据块副本（Value）；标志位：有效标志位、脏标志位

cache容量 = 行大小 × 行数  =（标记位位数+数据块位数+有效位1位+脏标志位1位） × 行数

>   [!NOTE]
>
>   直接相联映射的特点：
>
>   -   块映射速度快，一对一映射，无须查表
>   -   cache容易冲突，cache利用率低
>   -   命中率低，适合大容量cache
>   -   淘汰算法简单

>   [!NOTE]
>
>   【cache容量是指：（数据辅助位（tag+index）+能映射的数据容量）×行数】
>
>   【题】某计算机字长32位。主存容量4MB，按字节编址。Cache采用直接映射，Cache数据存储体容量为4KB，Cache块长度为8个字。 
>
>   1.   画出直接映射方式下主存地址划分情况。
>   2.   设cache初始状态为空，若CPU顺序访问0-99号单元，并从中读出100个字（设 主存一次读一个字），并重复此顺序10次，请计算cache命中率。
>   3.   如果cache的存取时间是20ns，主存访问时间是200ns，平均访问时间是多少。 
>   4.   Cache-主存系统访问效率

#### 4.5.6.3 组相联映射

![image-20250621213535305](D:\universityResource\_课程\计算机组成原理_大一下\pic\组相联映射.png)

全相联映射命中率高，但查找硬件成本高；而直接相联映射查找成本低，但命中率低，二者在特性上正好互补。组相联映射是直接相联映射和全相联映射两种方式的折中，既能提高命中率，又能降低查找硬件的开销。

**所以组相连映射可以看多直接相连加上全相连。**

图 4.41 所示为一个二路组相联的逻辑示意图，cache 一共包括 $n$ 组，同样也可以将主存地址中的主存块地址细分为标记字段 tag 和组索引 index 两部分。由图可知，cache 块大小 = $2^w$ 字节，组数 $n = 2^d$，主存容量 = $2^{s+w}$ 字节，cache 容量 = $2n \times (1 + s - d + 8 \times 2^w)$ 位。

### 4.5.7 替换算法

1.   先进先出法
2.   最近最不经常使用方法---LFU——替换最少使用的算法（保留重要数据）
3.   近期最少使用法--- LRU——替换最久没有被访问过的数据（替换冷数据）
4.   随机替换法
     1.   Cache容量增大，随机替换算法的功效仅稍逊与LFU和LRU算法
     2.   虚拟存储器的TLB表采用随机替换算法提高替换速度

## 4.6 虚拟存储器

采用 cache 技术可以大大提高主存的访问速度，<u>然而它并不能解决主存容量不足的问题</u>。目前，几乎所有的计算机中都采用了虚拟存储器系统。在存储系统的层次结构中，<u>虚拟存储器处于“主存 - 辅存”存储层次</u>，通过在主存和辅存之间<u>增加部分软件</u>（如操作系统）和<u>必要的硬件</u>（如地址映射与转换机构、缺页中断结构等，使辅存和主存构成一个有机的整体，就像一个单一的、可供 CPU 直接访问的大容量主存一 样。

-   其基本思路是加载程序时并不直接将程序和代码载入主存，而仅仅在相应的虚拟地址转换表（段表、 页表）中登记虚拟地址对应的磁盘地址。程序执行并访问该虚拟地址对应的程序或数据时，会产生缺页异常，操作系统会调用异常处理程序并载入实际的程序和代码。
-   **根据程序局部性原理，通常程序只需要加载很小一部分空间即可运行，这种方式避免了将程序全部载入主存，大大提高了主存的利用率。**
-   另外虚拟存储器也采用了和 cache 类似的技术，尽量将辅存中经常访问的程序和数据的副本调度到上层的主存储器中，使得大部分数据都可以通过直接访问快速的主存获得。极端情况下，主存空间也会消耗完毕（内存满），此时虚拟存储器需要选择最不经常访问的程序和数据进行淘汰，才能载入新的数据。淘汰时对于不可修改静态代码和数据，由于源数据来自辅助存储器，因此只需简单丢弃即可；而对于主存中动态修改过的数据，进行淘汰时则需要将这部分数据保存到辅助存储器上特殊的位置，并保存磁盘地址以便后续访问，较为常见的有Linux操作系统中的交换分区、Windows操作系统中的页面文件。这种机制使得主存满后系统仍然能正常运行，但由于辅存和主存访问速度差异巨大（$ms/ns $的量级差异），因此主存满后主存数据频繁地从主存到辅存的换入换出将导致系统性能急剧下降。

### 4.6.2 虚拟存储器的地址映射与变换

虚拟存储器中有 3 种地址空间，第一种是**虚拟地址空间**，也称为虚拟空间或虚地址空间，它是程序员用来编写程序的地址空间；第二种地址空间是主存的地址空间，也称**物理地址空间**或、实地址空间；第三种地址空间是**辅存地址空间**，也就是磁盘存储器的地址空间。与这 3 种地址空间相对应，有 3 种地址，即虚拟地址（虚地址）、主存物理地址（实地址）和磁盘存储器地址（磁盘地址或辅存地址）。

-   **虚拟存储器把虚拟地址空间映射到主存空间**，也就是将用户利用虚拟地址访问的内容按照某种规则从辅存装入主存储器中，并建立虚地址与实地址之间的对应关系。
-   而**地址转换**则是在程序被装入主存后，在实际运行时，把**虚拟地址转换成实地址或磁盘地址**，以便 CPU 从主存或磁盘中读取相应的信息。
-   在虚拟存储系统中程序运行时，CPU 以虚拟地址访问主存，使用存储管理控制部件**MMU(Memory Management Unit)**找出虚拟地址和物理地址之间的对应关系，并判断这个虚拟地址对应的内容是否已经在主存中。
    -   如果已经在主存中，则通过 MMU将虚拟地址转换成物理地址， CPU 直接访问主存单元；
    -   如果不在主存中，则把包含这个字的一页或一个程序段（与虚拟存储 器的类型有关）调入主存，并在 MMU 中填写相关的标记信息。

>   [!NOTE]
>
>   根据虚拟存储器中对主存逻辑结构划分的粒度不同，虚拟存储器可分成 3 种不同的类型， 分别是页式、段式和段页式虚拟存储器。
>
>   本章仅介绍页式虚拟存储器，段式、段页式虚拟存储可在操作系统课程中学习。

### 4.6.3 页式虚拟存储器

以页Page为逻辑结构划分信息传送单位的虚拟存储器称为页式虚拟存储器。在页式虚拟存储器中，虚拟空间和主存空间均被划分成固定大小的页。不同类型的计算机对页大小的划分不同，常见的页大小为4KB，也有更大容量的页。

#### 一、虚拟地址划分

![image-20250623155226237](D:\universityResource\_课程\计算机组成原理_大一下\pic\虚拟地址划分20250623155226237.png)

VPO 和 PPO 的位数相同，而 VPN 和 PPN 的位宽则分别取决于虚拟空间的容量和主存空间的容量。

#### 二、页表

<u>物理地址由 PPN 和 PPO 两部分构成（$物理页号 = PPN + PPO$），虚拟地址到物理地址的映射本质上就是将 VPN 转换成对应的PPN。</u>

页式虚拟存储器中虚拟地址与物理地址之间的转换是基于页表进行的。

-   页表是一张保存虚拟页号 VPN 和物理页号 PPN 对应关系的查找表，是一个由若干个表项组成的数组；

-   采用 VPN 作为索引进行访问，每一个表项主要包括有效位和物理页号，另外还包括修改位、使用位、权限位等信息，具体可在操作系统相关课程中进行深入了解。 

图 4.47 所示为页表逻辑结构示意图，图中主存和磁盘都分为固定大小的页面；**磁盘又分为交换分区和数据分区**：

-   交换分区用于存放主存页面换出的动态修改数据
-   数据分区用于存储用 户程序和数据。

主存和磁盘两部分空间合并构成虚拟地址空间。

![image-20250623155835963](D:\universityResource\_课程\计算机组成原理_大一下\pic\页表逻辑示意图.png)

由于每个进程都拥有独立的虚拟地址空间，因此**每个进程都有一张完整的页表**，**页表属于进程控制信息，存放在进程地址空间的内核区中**。

页表在主存中的首地址记录在页表基址寄存器 PTBR 中，进行进程切换时只需要简单地切换PTBR的值就可以实现页表的快速切换。

>   [!NOTE]
>
>   名词对照表：
>   VA（Virtual Address）：虚拟地址。
>
>   PA（Physical Address）：物理地址。
>
>   PTE（Page Table Entry）：页表项。
>
>   PTEA（Page Table Entry Address）：页表项地址。

-   当虚拟地址对应页表项中的有效位为 1 时，表明当前页的数据在主存中，直接利用页表中的物理页地址 PPN 与 VPO 一起生成物理地址即可访问主存数据。
-   而当有效位为 0 时，对应虚拟页可能是暂未分配页，如图中标记为 null 的页表项；
-   有效位为0 且 没有标记为 null 的页表项则表示对应页在磁盘中，访问对应页时会触发缺页异常，由操作系统的缺页异常处理程序负责将磁盘上对应的页载入主存中，并同时更新页表项，方便后续访问。

利用虚页号实现虚拟地址转换成物理地址 的过程如图 4.48 所示。

![image-20250623160329419](D:\universityResource\_课程\计算机组成原理_大一下\pic\基于页表的虚拟地址与物理地址的转换过程.png)

#### 三、虚拟存储器访问流程



# chap5 指令系统

## 5.1 指令系统概述

1.  **机器指令（指令）**：计算机能直接识别、执行的某种操作命令。
2.  **指令系统（指令集）**：一台计算机中所有机器指令的集合。
3.  **系列机**：基本指令系统相同，基本系统结构相同的计算机，如IBM、PDP-11、VAX-11、Intel-x86等。是为了**解决软件兼容的问题**。

![image-20250615174735949](D:\universityResource\_课程\计算机组成原理_大一下\pic\计算机系统中的指令系统层次.png)

## 5.2 指令格式

一条指令可以有多个或零个操作数，只有一个操作码，每个操作码对应一种操作指令。

指令集中的操作码可以分为定长操作码和变长操作码：

1.   **定长操作码**：操作码长度固定，位置固定。译码简单，利于硬件设计。
2.   **变长操作码**：操作码长度可变，位置不固定。采用扩展码技术实现变长操作码，操作码长度随着地址码数目减少而增加；压缩指令操作码的平均长度，用较短指令字长表示更多操作类型；早期计算机多采用此法。

猜测一种设计思路是：补零来保证定长，存在`000001`；另一种是只允许`0`以此来压缩操作码的平均长度，充分利用。

在32bit的操作码中，一种设计规范如下：

![image-20250615204217815](D:\universityResource\_课程\计算机组成原理_大一下\pic\指令字长32bit的操作码规范.png)

不同类型的操作码不能重叠，否则无法区分，下面的例题很好地体现了这一点：

>   [!IMPORTANT]
>
>   设某指令系统指令字长16位，每个地址码为6位。若要求设计二地 址指令15条、一地址指令34条，问最多还可设计多少条零地址指令？
>
>   1.   双操作数15=4+6+6：$2^4$
>   2.   单操作数16=10+6：$(2^4-15)\times 2^6$
>   3.   无操作数16=16：$((2^4-15)\times 2^6-34)\times 2^6$

## 5.3 寻址方式

运行程序时，不断地从主存取指令和数据，由于主存是基于地址访问的存储器，只有获得指令和操作数在主存中的地址（称为**有效地址 EA**）后，CPU 才能访问所需的指令和数据。寻址方式就是寻找指令或操作数有效地址的方法。

### 5.3.1 指令寻址

【指令寻址就是读取每一行指令的寻址方式】

主要分为顺序寻址和跳跃寻址两种。

#### 顺序寻址

指令在主存中顺序存放，执行完一条以后，通过让**程序计数器PC**加一，即PC+1，便能计算出下一条指令。其中1指的是一条指令的字节长度，如果是32位系统，则实际上需要`PC+4`。

#### 跳跃寻址

就是x86指令集中的`jmp`系列指令。学过`csapp`应该很容易理解。这个时候需要直接修改PC中的内容。

### 5.3.2 操作数寻址

地址码的构成：寻址模式Mode+形成地址D

设：实际有效地址是E，实际操作数是S，则可以表示成$S=(E)$

![image-20250615210835943](D:\universityResource\_课程\计算机组成原理_大一下\pic\指令中的操作数寻址方式构成.png)

【建议看图Page172/P159】

#### 5.3.2.1 立即寻址

```assembly
MOV EAX,2008H		# 为寄存器 EAX 赋初值 2008H
```

【立即数】

#### 5.3.2.2 寄存器寻址

```assembly
MOV EAX,ECX			# 将寄存器 ECX 中的内容送入寄存器 EAX 中
```



【给出寄存器编号，数据保存在对应寄存器中。】

#### 5.3.2.3 直接寻址

```assembly
MOV EAX,[2008H]		# 将 2008H 主存单元的内容送入寄存器 EAX 中
```

【给出主存地址，数据直接保存在主存地址中。】

#### 5.3.2.4 间接寻址

```assembly
MOV EAX , @2008H ; 			# @ 为间接寻址标志
```

【给出主存地址，在该主存处保存数据所在的真正的主存地址】

#### 5.3.2.5 寄存器间接寻址

```assembly
MOV AL,[EBX]			# 假设 EBX=2010H，主存 2010H 单元的内容为 60H，该指令执行后寄存器 AL 中							的内容为60H。
```

【给出寄存器编号，在该寄存器中保存数据所在的真正的主存地址】

#### 5.3.2.6 相对寻址

【相对寻址是把程序计数器 PC 中的内容加上指令中的形式地址 D，形成操作数的有效地址， 因此 EA=PC+D，S=(PC+D)。相对寻址过程如图 5.9 所示。】

【同时需要注意，因为取指令过程中 PC 的值会修改，也就是在读取完这一句指令以后PC中的值实际上是下一句指令的PC，所以有 EA=PC+1+D。注意 1 是 1 条指令的字节长度。】



>   [!NOTE]
>
>   **下面的例题很能说明问题**：
>
>   某计算机指令字长为定长 16 位，内存按字节寻址，指令中的数据采用补码表示， 且 PC 的值在取指令阶段完成修改。完成下列有关相对寻址的问题。
>
>   根据题意，采用相对寻址指令的地址为 2003H，PC 在取指令完成后修改，则取指 令完成后 PC=2003H+2H=2005H（因为指令字长 16 位占用两个主存单元），所以 D=200AH– 2005H=5H。

#### 5.3.2.7 变址寻址

在变址寻址方式下，指定一个寄存器用来存放变化的地址，这个寄存器称为变址寄存器，此时形式地址字段 D 应该增加一个变址寄存器编号字段 X。变址寄存器 X 与形式地址 D 之和即为操作数的有效地址，也就是 EA=R[X]+D。变址寻址的过程如图 5.10 所示。

```assembly
OV EAX,32[ESI]			# 将变址寄存器 ESI 的值加上偏移量 32 来形成地址访问主存，并将结果送到 							EAX
```

>   [!NOTE]
>
>   有时候会有种自增的情形，表示为$(R_n)+$，这样的会先把$R_n$的内容自增1个字长，再去寻址。【做题时需要注意这一点】

---

例题：

![image-20250615224350219](D:\universityResource\_课程\计算机组成原理_大一下\pic\寻址系统例题.png)

---

## 5.4 指令类型

在计算机科学领域，指令分类是理解和设计计算机体系结构的重要部分。指令集是计算机能够理解和执行的一系列操作的集合，而这些操作可以根据不同的特征进行分类。不同的计算机架构，如x86和MIPS，有着各自独特的指令集，但它们都可以按照一定的规则进行分类。

### 5.4.1 指令分类方式

-   指令可以根据计算机系统的层次结构进行分类。这种分类方法将指令分为**微指令、机器指令和宏指令**。微指令是最低级别的指令，通常由硬件直接执行。机器指令是程序员直接编写或由编译器生成的指令，它们是计算机可以直接执行的指令。**宏指令则是由一系列机器指令组成的，通常用于实现更复杂的操作。**

-   指令可以根据操作数的物理位置进行分类。这种分类方法将指令分为**存储器-存储器（SS）型**、**寄存器-寄存器（RR）型**和**寄存器-存储器（RS）型**。存储器-存储器型指令的操作数都在存储器中，寄存器-寄存器型指令的操作数都在寄存器中，而寄存器-存储器型指令的操作数则在寄存器和存储器之间。

-   指令还可以根据其长度进行分类，分为**定长指令**和**变长指令**。定长指令的长度是固定的，这使得计算机能够快速地识别和执行它们。变长指令的长度则可以根据需要进行变化，这使得指令集更加灵活，但同时也增加了指令解码的复杂性。

-   指令可以根据操作数的数量进行分类，分为**四地址**、**三地址**、**二地址**、**单地址**和**零地址**指令。这种分类方法反映了指令操作数的数量和复杂性，对于理解指令的执行过程和优化指令集设计具有重要意义。

-   指令可以根据其功能进行分类。这种分类方法将指令分为**数据传送类**、**算术运算类**、**逻辑运算类**、**程序控制类**、**输入/输出类**和**其他类**。数据传送类指令用于在不同存储位置之间移动数据，算术运算类指令用于执行基本的数学运算，逻辑运算类指令用于执行逻辑操作，程序控制类指令用于控制程序的执行流程，输入/输出类指令用于处理输入和输出操作，而其他类指令则包括一些特殊的操作，如标志操作和系统调用。

### 5.4.2 经典指令集中的分类

在具体的指令集设计中，如x86和MIPS，指令的分类和实现有着各自的特点。

-   x86指令集是复杂指令集计算机（CISC）的代表，它包含了大量的指令，每个指令可以执行多种操作。例如，x86指令集中的数据传送类指令包括MOV指令，用于将数据从一个位置传送到另一个位置。算术运算类指令包括加法、减法、乘法和除法等操作。逻辑运算类指令包括NOT、AND、OR、XOR和TEST等操作。程序控制类指令包括无条件转移、条件转移、子程序调用和返回等操作。输入/输出类指令包括IN和OUT指令，用于处理输入和输出操作。其他类指令则包括标志操作和系统调用等。

-   MIPS指令集则是精简指令集计算机（RISC）的代表，它具有更少的指令和更简单的指令格式。MIPS指令集的运算指令包括算术、逻辑和移位操作。分支指令用于控制程序的执行流程，包括条件分支和无条件分支。访存指令用于在寄存器和存储器之间移动数据。系统指令则包括系统调用、中断处理等操作。

总的来说，指令分类是理解和设计计算机体系结构的重要工具。通过对指令进行分类，我们可以更好地理解指令的执行过程，优化指令集设计，并提高计算机的性能和效率。无论是在复杂的x86指令集还是在精简的MIPS指令集中，指令分类都发挥着关键的作用。

## 5.5 指令集格式的设计

【这一部分很简单】

【PPT中的一道例题是去年的真题】

## 5.6 CISC与RISC

复杂指令集计算机（Complex Instruction Set Computer，CISC）和精简指令集计算机（Reduced Instruction Set Computer，RISC）的指令系统不同，它们的区别在于采用了不同的 CPU 设计理念和方法。

### 5.6.1 CISC 

随着超大规模集成电路技术的持续进步，计算机硬件成本逐渐降低，而软件成本则不断上升。为了应对这一趋势，计算机系统设计者在设计指令系统时，采取了以下措施：

1.  **增加功能强大的复杂指令和更多的寻址方式**，以满足不同需求，包括：
    -   更好地支持高级语言：通过增加语义接近高级语言语句的指令，缩短指令系统与高级语言之间的语义差距。
    -   简化编译过程：当机器指令的语义与高级语言的语义接近时，编译器设计更简单，编译效率提高，目标程序也更优化。
    -   满足系列计算机软件向后兼容的需求：为了程序兼容，同一系列新型计算机和高档计算机的指令系统只能扩充，不能减少原有指令，导致指令数量增多。
    -   对操作系统的支持：随着操作系统功能的复杂化，指令系统需要提供相应功能指令的支持，如多媒体指令和3D指令等。
    -   在有限指令长度内基于扩展法实现更多指令：为满足寻址访问的需要，必须设计多种寻址方式，如基址寻址、相对寻址等，同时最大限度地压缩地址码长度。

基于上述原因，指令系统变得越来越庞大和复杂。



在某些计算机中，**指令数量多达数百条**，寻址方式的种类也很多，这类计算机被称为复杂指令系统计算机（CISC）。**Intel x86和IA64指令系统是典型的CISC指令系统**。

CISC具有以下特点：

1.  指令系统复杂庞大，指令数目一般多达二三百条。
2.  寻址方式多样。
3.  指令格式多样。
4.  指令字长不固定。
5.  对访存指令不加限制。
6.  各种指令使用频率差异大。
7.  各种指令执行时间差异大。
8.  大多数采用微程序控制器。

这种设计虽然增加了指令系统的复杂性，但也提高了计算机的灵活性和功能，以适应不断变化的软件需求和技术发展。

### 5.6.2 RISC

人们进一步分析 CISC 后发现了二八规律，即在 CISC 的典型程序中，80％的程序只用到了 20％的指令集，基于这一发现，精简指令集的概念被提出来，这是计算机系统架构的一次深刻革命。

精简指令系统计算机（RISC）体系结构的基本思路是：针对 CISC 指令系统指令种类太多、 指令格式不规范、寻址方式太多的缺点，通过减少指令种类、规范指令格式和简化寻址方式来 方便处理器内部的并行处理，从而大幅度地提高处理器的性能。

RISC 是在继承 CISC 的成功技术并克服 CISC 缺点的基础上产生并发展起来的，大部分 RISC 具有如下特点：

-   优先选取使用**频率最高**的一些简单指令，以及一些很有用但不复杂的指令，**避免使用复杂指令**。
-   **大多数指令在一个时钟周期内完成**。
-   **采用 LOAD/STORE 结构。**由于访问主存指令花费时间较长，因此在指令系统中应尽量减少访问主存指令，只允许 LOAD（取数）和 STORE（存数）两种指令访问主存，其余指令只能对寄存器操作数进行处理。 
-   **采用简单的指令格式和寻址方式，指令长度固定。**固定的指令格式。指令长度、格式固定，可简化指令的译码逻辑，**有利于提高流水线的执行效率**。
-   为了便于编译的优化，**常采用三地址指令格式**。
-   **面向寄存器的结构。为减少访问主存，CPU 内应设大量的通用寄存器。**
-   **采用硬布线控制逻辑。**由于指令系统的精简，控制部件可由组合逻辑实现，**不用或少用微程序控制**，这样可使控制部件的速度大大提高。
-   注重编译的优化，力求有效地支持高级语言程序。

RISC 的着眼点没有简单地放在简化指令系统上，而是通过简化指令使计算机的结构更加简单合理，从而提高处理速度，其主要实现途径是减少指令的执行周期数。现在，RISC 的硬件结构有很大改进，一个时钟周期平均可完成 1 条以上指令，甚至可完成几条指令。

**较为常见的 RISC 指令系统有 ARM、MIPS、RISC-V 等。**

---

课本上没有提及，但是我认为CSAPP中的说法值得参考：两者成融合趋势。

---

## 5.7 指令集举例

建议学习CSAPP。我觉得学CSAPP中的内容对于国内大一学生已经够了。

# chap6 中央处理器

中央处理器（Central Processing Unit，CPU）由运算器和控制器组成，是整个计算机的核心。它根据指令的要求指挥协调计算机各部件的工作，并且对信息处理过程中出现的异常情况进行处理。本章主要介绍中央处理器的基本功能与组成、指令周期的基本概念、数据通路及指令操作流程、时序与控制、硬布线控制器的组成原理与设计方法、异常及中断处理等内容。 

```
6.1 中央处理器概述
6.2 指令周期
6.3 数据通路及指令操作流程
6.4 时序与控制
6.5 *硬布线控制器
6.6 微程序控制器
6.7 *异常与中断处

## 课件目录 打（*）不学
```

## 6.1 中央处理器的概述

![image-20250616072813395](D:\universityResource\_课程\计算机组成原理_大一下\pic\chap6计算机组织结构.png)

### 6.1.1 中央处理器的功能

CPU 的主要功能是执行程序，CPU 上电复位后即开始周而复始地取指令、执行指令工作。作为执行程序的基本功能部件，从保证程序功能正确性的角度看，CPU 应该具有以下几方面的功能：
1. **程序控制-确保代码执行顺序。**控制程序中指令执行的顺序，即控制程序中的指令按事先规定的顺序自动地执行。冯·诺依曼计算机中程序指令通常按顺序执行，遇到分支指令且分支条件满足时会改变执行顺序，CPU 必须能够正确地确定下条指令的地址。
2. **操作控制-实现代码指令的实现**。操作控制是指产生指令执行过程中需要的操作控制信号，以控制执行部件按指令规定的操作正确运行。例如执行加法指令时，CPU 必须生成运算器的运算选择控制信号，以保证其进行加法操作。
3. **时序控制。**时序控制是指对每个操作控制信号进行定时，严格控制每个操作控制信号的开始时间和持续时间，以便按规定的时间顺序执行各操作，控制各功能部件。对任何一条指令而言，如果操作控制信号的时间不正确，则指令的功能就不能正确实现。
4. **数据加工-数据的计算和传递**。数据加工即对数据进行算术、逻辑运算，或将数据在相关部件之间传送。
5. **中断处理-处理异常。**CPU 应能及时响应内部异常和外部中断请求，如 CPU 在执行指令过程中 出现“未定义指令”，运算时出现异常（整数除零）、访问指令或数据时发生“缺页”，外部设备发生中断请求时，CPU 应能暂时中断当前执行的程序并进行异常或中断处理，完成处理后还应返回断点继续执行程序。

【其中，数据加工由运算器负责，其余由控制器负责】

### 6.1.2 中央处理器的组成

#### 6.1.2.1 寄存器

| 寄存器名称                | 描述           | X86    | MIPS   |
| ------------------------- | -------------- | ------ | ------ |
| PC (Program Counter)      | 程序计数器     | EIP    | PC     |
| IR (Instruction Register) | 指令寄存器     | [可选] | [可选] |
| AR (Address Register)     | 地址寄存器     | MAR    | [可选] |
| DR (Data Register)        | 数据缓冲寄存器 | MDR    | [可选] |
| AC (Accumulate Count)     | 累加寄存器     | [可选] | [可选] |
| PSW (Program Status Word) | 程序状态字     | EFLAGS | 无     |

- **MAR (Memory Address Register)**: 地址寄存器
- **MDR (Memory Data Register)**: 数据缓冲寄存器

##### 简单CPU模型（寄存器）

![image-20250616073317296](D:\universityResource\_课程\计算机组成原理_大一下\pic\chap6简单CPU模型（寄存器）.png)

#### 6.1.2.2 操作控制器 

CPU（中央处理器）中的操作控制器（Control Unit，简称CU）是CPU内部的一个关键组件。个人认为，除了运算以外的所有工作，都由操作控制器负责，具体包括：指令获取、指令译码、操作控制、时序控制、中断处理、微操作、状态监控、分支预测…它**循环进行取指、执行、处理异常的操作**。

**取指**：根据PC中的下一条指令地址，从主存中取出指令。

**执行**：将机器指令译码并生成执行部件所需的控制信号序列，控制信号按序送至各执行部件控点，引起逻辑门开闭，建立正确的数据通路，从而完成指令功能。

-   操作控制器接收指令译码器（ID）送来的指令译码信息，与时序信号、条件及状态信息进行组合，形成各种具有严格时间先后顺序的操作控制信号（即微操作控制信号序列），并连接到计算机各功能部件的控制端，控制相应部件按指令的功能依序进行动作，从而实现指令的功能。

-   CPU执行指令的过程就是CPU控制信息流的过程，操作控制器是控制的决策机构，其产生的微操作控制信号序列就是控制流。信息流的控制就是将操作控制器生成的微操作控制信号序列送到各功能部件的控制门、多路选择器、触发器或锁存器处，依时间先后顺序打开或关闭某些特定的门电路，使数据信息按完成指令功能需要经过的路径——数据通路从一个功能部件传送到另一个功能部件，实现对数据加工处理的控制。

在硬件上，控制器可以分为两类：**硬布线控制器** (时序逻辑型)和**微程序控制器** (存储程序型)

## 6.2 指令周期

### 6.2.1 指令执行的一般流程

程序执行时，取指令和执行指令的操作反复执行。因为指令功能和寻址方式不同，对应的数据通路和执行时间也不相同，比如：加法、除法、访存指令等等，需要的时间都不相同。下图是有分支指令时的指令执行流程图示例：

![image-20250616102204023](D:\universityResource\_课程\计算机组成原理_大一下\pic\指令执行流程图_有分支.png)

### 6.2.2 指令周期基本概念

-   时钟周期 = 节拍脉冲 = 振荡周期，能完成一次**微操作**（执行部件控点的逻辑门开闭）

-   时钟信号：晶体振荡器产生的一个固定频率（时钟频率，时钟周期倒数）的方波信号

-   机器周期 = CPU周期 = 包含K个节拍：从主存读出一条指令的最短时间，可完成一次 复杂操作

-   **指令周期**：从主存取一条指令并执行指令的时间，包含**取指令周期**和**执行指令周期**。每个执行周期包含0~n个机器周期，n取决于指令功能、寻址方式、指令执行结束时是否有中断

>   [!NOTE]
>
>   注意指令周期的机器周期数以及每个机器周期所包含的时钟周期数并不一定是固定的，和具体实现有关，通常分为**定长指令周期**和**变长指令周期**两种。
>
>   -   定长指令周期中所有指令的指令周期相同、机器周期数固定，机器周期所包含的节拍数也是固定的，如早期的三级时序系统。
>
>   -   现代计算机普遍采用以时钟信号进行定时的变长指令周期，不同指令的机器周期数可变，按时钟周期同步，一条指令的执行需要多少个时钟周期就安排多少个时钟周期，机器周期的概念也逐渐消失。 
>
>   【变长指令中PC+1操作的执行顺序也不同，因为需要等到译码器对下一个指令周期进行译码，才能确定“1”的大小】

关于时序同步的详细内容将在 6.4 节“时序与控制”中详细介绍。

## 6.3 数据通路及指令操作流程

### 6.3.1 数据通路模型与定时

-   数据通路——执行部件间传送信息的路径（数据流）。
    -   不同指令、同一指令执行的不同阶段，数据通路不同
    -   运算器与各寄存器之间的传送路径就是CPU内部的数据通路
-   通路的建立由控制信号控制，受时钟驱动 （控制流）

数据通路有多种类型：

1.   共享通路（总线型）：主要部件都连接在公共总线上，各部件间通过总线进行数据传输。

     **结构简单，实现容易，但并发性较差，需分时使用总线，效率低**

2.   专用通路：并发度高，性能佳，设计复杂，成本高，可以看作多总线结构

### 6.3.2 单总线结构的数据通路

CPU 中的运算器、控制器、寄存器堆等核心部件均通过一条内部的公共总线连接起来。

同一时刻只有一个部件向总线输出数据。

数据传输只能**分时**使用总线。

### 6.3.3 专用通路结构的数据通路

基本特征：

1.   各功能部件之间均基于专用的数据传输通路连接
2.   各通路中的数据可并行传输，控制较总线结构要简单

单周期：

1.   所有指令一个时钟周期完成，CPI=1，但时钟频率取决于最慢的指令（通常是访存指令）
2.   数据、指令分开存放（哈佛结构）：保证取指令和取操作数并行
3.   运算PC、运算分支地址、运算数据所需的运算器需分别设置，成本较高
4.   控制器为组合逻辑：所有的控制信号在一个周期内产生，没有时序
5.   不能设置AR,DR,IR等寄存器

## 6.6 微程序控制器



---

？END【第六章不完整，第七章暂未纳入考点】【以期末考试要求】

---

# chap8 总线系统

现代计算机系统采用总线技术将 CPU、主存以及输入输出设备等计算机功能部件连接起来，并通过总线在各功能部件之间传送地址信息、数据信息、控制信息，方便各功能部件之间协同工作，从而实现数据的处理、传输和存储，总线技术对计算机系统的性能有较大的影响。

## 8.1 总线概述

**早期总线**是指连接多个计算机硬件功能部件的一组公共的并行传输信号线缆，用于在各功能部件之间进行信息传输，如图 8.1 所示。所有功能部件均通过特殊的硬件接口直接连接到共享总线上，这种方式相对点对点的分散连接方式可有效减少连接线路的数目以及硬件端口数，使传输控制更简单，有效降低了设计复杂度和成本，增加新设备更容易、可扩展性高。

![image-20250616152828574](D:\universityResource\_课程\计算机组成原理_大一下\pic\总线和分散连接（早期简单示意图）.png)

早期总线的主要功能是在连接的功能部件之间进行数据传输。由于总线被与之连接的多个功能部件共享，为避免信号冲突，同一时刻只允许一个功能部件向总线发送信息；但可以有多个设备同时接收数据。各功能部件只能分时地使用共享总线，相比分散连接方式，其传输效率较低。

**现代总线是指连接多个计算机内部功能部件或多个计算机的通信系统，总线既包括相关的硬件（总线控制器、总线接口）、软件，也包括相关的通信协议。**现代计算机总线除了包括传统的**并行总线**，如早期的 ISA、EISA 总线和仍在使用的 PCI 总线，还包括串行传输的**串行总线**， 如 USB、PCIe、SATA 等总线；连接方式既可以是常见的**多端口总线**，也可以是**菊花链结构**，甚至还可以是**交换网络结构**。方便计算机系统的集成、扩展和进化。

>   [!WARNING]
>
>   总线不应成为整个计算机性能的瓶颈

### 8.1.1 总线分类

-   按传输方向分：单向传输总线、双向传输总线

-   按时序控制分：同步总线（公共时钟）、异步总线（应答机制）

-   按信号功能分：数据总线、地址总线、控制总线
-   按信号传输模式分：并行传输总线、串行传输总线
-   按传输速度分：高速总线、中速总线、低速总线
-   按总线所处位置分
    -   **片内总线** ：CPU内各功能单元间的连线：ARM公司的AMBA总线
    -   **内部总线**
        -   **系统总线**：CPU直接连接主存、I/O模块等主要部件的连线，也称为主机总线、CPU总线、前端总线等；例如PCI、AGP等
        -   **I/O总线**：连接计算机内部的中低速I/O设备，通过桥接器与高速总线连接； 例如ISA、连接磁盘设备的PATA、SATA等
    -   **外部总线**：计算机与外部设备（如控制仪表、移动通信等，系统之间差异较大）的连线，也称通信总线;；例如USB、火线（IEEE-1394）等

### 8.1.2 总线组成

**总线系统通常包括一组连接各功能部件的传输线缆和总线控制器。**

**总线控制器**负责*总线控制权的仲裁*以及*总线资源的分配和管理*，如果是扩展总线控制器还需要进行*总线协议转换*。图 8.2 所示的系统总线中总线控制器就是 CPU 内部的总线接口单元 BIU。

-   **所有设备都必须通过总线接口与总线连接**，这里 DRAM 通过内存控制器、I/O 设备通过 I/O 接口与总线相连。
-   **总线接口**是总线与其连接部件之间的物理和逻辑界面，主要用于负责设备寻址、设备控制、数据输入 输出、速度缓冲、串并转换等，相关内容将在第 9 章进行详细介绍。
-   **连接线缆**：数据总线（总是双向总线），地址总线（单向总线），控制总线（对于一根来说是单项的，对于整体来说是双向的）。

![image-20250616154419608](D:\universityResource\_课程\计算机组成原理_大一下\pic\总线互联方式.png)

#### 8.1.2.1 总线的功能

#### 8.1.2.2 总线复用技术

**总线的信号线分为专用和复用两种**。
- 专用信号线只用于传输一种信号，系统总线的3种总线就是专用总线。
- 而复用总线是指一组传输线具有多种用途，用于分时传送不同类型的信息。最常见的是地址总线和数据总线复用，即地址总线和数据总线共用一组物理线缆，某一时刻该总线传输地址信号，另一时刻传输数据信号。总线复用技术可以减少引脚数目，PCI 总线就是典型的复用总线。
- **同一功能的线缆也可以复用**，例如 DRAM 芯片的行列地址线就是复用的，在不同的时钟周期分别传送行、列地址，大大减少了芯片的引脚数。
- **串行总线也可以看作一个非常极端的总线复用**，所有的信息都是通过同一根线缆或两根线缆（**差分模式**）进行传递的。

>   [!NOTE]
>
>   **总线复用的优势**：提高总线的利用率，减少引脚数目和布线空间，降低成本
>
>   **总线复用的缺点**：控制模块复杂，另外分时传送机制还会引起总线性能下降。
>
>   在具体设计过程中是采用专用方式还是采用复用方式，需要根据部件的功能和性能要求来确定，在需要采用并行传送方式来实现部件功能或提高传输性能的场合，就不宜采用总线复用方式。

#### 8.1.2.3 总线设备分类

-   可以拥有总线控制权并主动进行总线传输控制的设备称为**主设备**，而被主设备寻址访问的设备称为**从设备**

-   主设备既可以发送数据给从设备，也可以接收从设备的数据。
-   在总线传输的过程中，主设备是主动的，能主动发起总线传输；而从设备只能被动响应。
-   同一时刻只允许有一个活动主设备控制总线，如果主设备采用广播方式发送数据，则可以有多个从设备存在。

### 8.1.3 总线标准

总线结构最大的优势就是**成本低廉、可扩展性高**。

**制定总线标准的重要性来源**：

-   包括 CPU 在内的所有设备都必须通过总线接口（I/O接口）连接到总线上，不同厂商的设备要连接到同一总线上必须遵循相同的总线标准。
-   总线标准化有利于不同厂商分工协作生产出标准化的计算机，使相同功能的部件可以互换使用， 极大地推动了计算机的发展。

>   [!NOTE]
>
>   一些知名标准及其发展：IBM 公司的 PC/XT 总线标准就直接开启了兼容机的时代。后来又发展出了 16 位的 ISA 总线标准，32 位的 EISA、VESA、PCI 总线标准。

-   总线标准：关于总线与总线接口的物理特性、电气特性、功能特性、时间特性的详细规范和协议
    -   物理规范：规定总线的物理连接方式，如根数，插头插座的形状，引线的排列方式
    -   电气规范：信号线的传递方向：单/双向；有效电平：电平高有效/低有效及范围
    -   功能规范：定义信号线的功能：地址、数据、控制
    -   时序规范：同步、异步；多路复用：地址线和数据线能否共用一条物理线

### 8.1.4 总线与三态门

**由于总线设备输出的二进制信号较弱，当总线比较长且设备较多时，很难驱动总线进行正常工作。**

为了保证总线数据传输的可靠性，所有总线上连接的设备均通过总线接口芯片与总线连接，而对这些接口芯片通常采用三态门进行控制。【**接口芯片用三态门对总结进行控制**】三态门可以控制设备与总线的连接，在设备不需要和总线连接时可以使其和总线断开，降低总线负载；三态门具有信号缓冲放大的功能，可以增强信号的驱动能力；**三态门还可以控制总线的传输方向**。

**三态门又称三态缓冲器，通常采用宽高比很大的 MOS 管实现，其输出信号驱动能力较高。**

![image-20250616161155648](D:\universityResource\_课程\计算机组成原理_大一下\pic\三态门及其等效电路.pbg)

下面是两种应用场景的实例：

![image-20250616161523618](D:\universityResource\_课程\计算机组成原理_大一下\pic\三态门的两种典型应用.png)

### 8.1.5 总线性能指标（计算相关）

总线的性能指标主要包括如下参数：

1.   **总线宽度**：它是指数据总线的根数，用位（bit）表示，如 8 位、16 位、32 位等。在并行传输总线中数据总线宽度直接决定了可并发传输的位数。

2.   **总线时钟频率**：它是总线时钟周期的倒数，同步传输总线中传输双方拥有完全同步的时钟信号，时钟频率越快，传输速率越快；早期总线的时钟频率和 CPU 是同频的，后来 CPU 发展太快，总线时钟开始独立于 CPU 时钟。

3.   **总线传输周期**：指一次总线操作完成所需要的时间，包括总线申请阶段、寻址阶段、传输阶段和结束阶段 4 个阶段的时间，简称总线周期；通常包括多个总线时钟周期，总线的时钟频率越高，总线周期就越短；**另外如果采用地址复用技术，则会增加总线周期**。**通常一个总线周期只能传输一个总线宽度的数据**。

4.   **单时钟传输次数**：指一个总线时钟周期内传输数据的次数，通常该值为 1；DDR 技术 在时钟上、下跳沿分别传输一次数据，该值为 2；QDR 技术下其值为 4（总线内部时钟为两个相 位相差 90°的时钟）。目前该值最高的是 AGP x8 总线，单时钟可以传输 8 次。$总线的实际工作 频率 = 总线时钟频率 \times 单时钟传输次数$。

5.   **总线带宽**：指在总线上的最大数据传输速率，通常不考虑总线传输周期中总线申请和寻址等阶段的开销，单位是 MB/s 或 GB/s（$1MB=10^6$字节，$1GB=10^9$字节）；**注意通信领域和磁存储领域并没有使用 1024 作为基本单位**。

总线带宽计算公式如下： **同步总线带宽 = 总线宽度 × 总线时钟频率 × 单时钟传输次数**

6.   总线负载能力：指总线上能同时连接的设备数，如 PCI 总线插槽通常只能外接 3 个扩展设备。

>   [!NOTE]
>
>   通常计算机系统都会追求总线的高带宽和较强的负载能力，但部分总线性能指标有可能是互相矛盾的。例如并行总线时钟频率提高后，会引起线间串扰和时钟偏移问题，降低传输可靠性，从而影响总线带宽，另外还可能影响总线的负载能力。在实际设计过程中会根据实际需求，以及当时的技术、工艺水平进行合理的折中考虑。

>   [!NOTE]
>
>   例题：某 32 位同步总线时钟频率为 400MHz，每个总线时钟周期可以传输一个机器字，为优化总线性能，将总线宽度增加到 64 位，并采用了 QDR 技术，一个总线时钟周期可以传输 4 次，则总线的带宽是多少，提高了多少倍？ 
>
>   解：由同步总线带宽计算公式，可得： 
>
>   数据传输速率 = $4B \times 400MHz \times 1 = 1.6 GB/s$ 
>
>   总线改进后的带宽 = $ 8B \times 400MHz \times 4 = 12.8 GB/s $
>
>   提高了 8 倍。

## 8.2 总线传输机制

### 8.2.1 总线传输过程

一次完整的总线传输过程依时间先后顺序可细分为以下 4 个阶段：

1.   请求阶段：需要使用总线的主设备通过控制总线发出总线请求信号，由总线控制器决定将下一个总线使用权分配给哪一个请求者，申请总线的主设备收到总线许可信号后才能使用总线。请求阶段可进一步细分为**传输请求**和**总线仲裁**两个阶段。
2.   寻址阶段：获得总线使用权的**主设备**通过总线发出**目标从设备**的存储器地址或 I/O 端口地址以及有关控制命令，启动相应的从设备，与地址总线中的地址相匹配的从设备会进行自动响应。
3.   传输阶段：也称数据阶段，主要用于实现主设备和从设备之间的数据传输，既可以是主设备向从设备发送数据，也可以是主设备从从设备获取数据，通常一次传输只能传输一个计算机字长的数据。
4.   结束阶段：传输阶段结束后进入结束阶段，主设备应撤销总线请求，释放总线控制权，以便总线控制器重新分配总线使用权。

#### 总线事务

通常把总线上一对主从设备之间的**一次信息交换过程**称为一个**总线事务 Bus Transaction**，总线事务类型通常根据它的操作性质来定义。典型的总线事务类型有“存储器读”“存储器写”“I/O 读”“I/O 写”“中断响应”“DMA 响应”等。

-   普通模式：一个寻址阶段+一个数据阶段
    -   寻址阶段：发送一次地址信息
    -   数据阶段：传输一个数据
-   突发(猝发)传送事务（Burst Mode），成组传送事务，一个寻址阶段+多个数据阶段
    -   寻址阶段：发送连续数据单元的首地址
    -   数据阶段：传送多个连续单元的数据，传输过程不释放总线


![image-20250617134244557](D:\universityResource\_课程\计算机组成原理_大一下\pic\普通模式总线传输和突发模式总线传输对比.png)

不同类型的总线所支持的事务类型不同，如 ISA 总线支持 8 种事务类型，而 Pentium Pro 处理器的总线事务类型多达 11 种。

### 8.2.2 总线的信息传送

#### 8.2.2.1 信息传送方式

总线上的信息以**电信号**的形式传送，用电位的高低或脉冲的有或无代表信息位的“1”或“0”。 通常，总线信息的传送主要有**并行传送**、**串行传送**、**并串行传送**和**分时传送** 4 种。

##### 并行传送

并行传送是指一个信息的所有位同时传送，每位都有各自的传输线，互不干扰，一次传送整个信息，如图所示。一个信息有多少位，就需要多少条传输线。并行传送一般采用电位传输法，位的次序由传输线排列而定。 

**并行传送的优点是传送速度快；缺点是线数多，成本高，传输距离较长时会产生时钟偏移问题。**因此其只适合近距离传输，计算机中系统总线普遍采用并行传输方式。

![image-20250617134731790](D:\universityResource\_课程\计算机组成原理_大一下\pic\并行传输.png)

---

当传输频率过高时还会引起线间串扰问题，存在高频障碍，因此现代总线逐渐向高频串行总线发展，发展出 PCIe、SATA 等高速**串行总线**。

---

##### 串行传送

**现代总线发展趋势是高频串行总线**。

串行传送是指将数据逐位按顺序以脉冲方式传送，一次只能传送一个比特位的数据，串行传送只需要一条传输线（差分方式需要两条）。串行传送成本低且传输距离远，最远可达几千米，同等频率下比并行方式的传输速率低。由于信息在 CPU 内部通常都是并行处理的，因此要将信息以串行方式传送，在发送端和接收端分别需要增加并串转换和串并转换电路。

位信息从低到高在一条传输线上逐位以脉冲方式传送：

-   一条传输线，每次一位，先传低位，后传高位【比如：第一个时间间隔传递最低位】
-   发送端往往需要进行并_串转换，在接收端进行_串并转换
-   成本低，速度慢，传输距离长。

![image-20250617135055372](D:\universityResource\_课程\计算机组成原理_大一下\pic\串行传送.png)

1.   根据**传送方向**的不同，串行传送可以进一步分为**单工**、**半双工**和**全双工** 3 种，如图 8.8 所示。 单工方式只能进行固定方向的单向传送；半双工方式能进行双向传送但不能同时进行双向传送；全双工方式能够同时进行双向传送，要实现全双工必须包括两组传输线，且双方都应该设置发送器和接收器。
2.   根据**定时方式**的不同，串行传送分为**同步串行通信**和**异步串行通信**两种。【了解即可，详细见Page309/P296】
     1.   同步串行通信传输双方采用统一时钟，除数据传输线外还应包括时钟线，时钟由发送方提供，这样接收方可以使用相同的时钟采样数据传输线中的每个信息位；传输线上的一个高电平代表几个数据位取决于采样频率。同步串行通信方式将多个字节数据组成一个信息帧进行传输，信息帧大小为几十到几千个字节不等，每帧的开始用一个或两个特殊的同步字符来指示传送开始，结尾也有相同的结束字符指示传送结束。
     2.   异步串行通信传输双方各自都有独立的时钟，但传输双方应该按约定的速率发送和接收数据，传输时利用信息帧中的起、停信号来进行数据同步。

>   [!NOTE]
>
>   【串行传输的计算】
>
>   -   串行传送的数据格式编码
>       -   起始位+数据位+校验位+停止位
>   -   波特率: 单位时间传送的二进制位数（bits/s）
>   	- 包括起始位、停止位、校验位
>   - 	数据传输率：单位时间传送的有效数据位
>   	- 不包括启停位及校验位，小于波特率
>
>   【例8.2】 若异步串行传输的信息帧由1个起始位、7个数据位、1个奇偶校验位和1个停止位等10个数位构成，线路每秒钟传送120个字符，分别计算波特率和 数传率。 
>
>   解： 波特率 = 10位／字符 × 120字符／秒 = 1200 bps = 1200波特
>
>   ​	数传率 = 120 × 7位/秒 = 840 bps
>
>   【多组串行通路并发计算】
>
>   串行传输解决了高频传输的问题，但带宽有限。
>
>   高速串行总线普遍采用**多组串行通路并发**来提升总线带宽：
>
>   -   每条传输线上串行传输数据，但有多个串行传输线并发工作同时传输多个数据
>   -   如PCIe x1、x4、x16中的数字就是并发通路数
>   -   串行总线带宽 = 总线时钟频率 × 编码效率 × 并发通路数
>
>   【例题】PCIe 3.0显卡接口的工作频率为8GHz，最大并发通路为40路，总线编码方式为128bit/130bit，支持全双工传输。请计算其总线带宽。 
>
>   解：单向带宽 = 总线时钟频率 × 编码效率 × 并发通路数 = 8GH × 128/130 × 40 / **8** = 39.4 GB/s ≈ 40 GB/s 全双工模式总线带宽 = 2 × 39.4 GB/s = 78.8 GB/s ≈ 80 GB/s

![image-20250617141111502](D:\universityResource\_课程\计算机组成原理_大一下\pic\编码效率.png)

##### 并串行传送

并串行传送将被**传送信息分成若干组，组内采用并行传送，组间采用串行传送**。

它是对传送速度与传输线数进行折中的一种传送方式。

例如，在 Intel 8088 CPU 中，CPU 内部数据通路为 16 位，CPU 内部采用并行传送；但系统总线只有 8 位，CPU 与主存或外部设备通信只能采用并串行传送，即将一个 16 位字分成两个连续的 8 位字节进行串行传送。例 8.3 中的 `PCIe 3.0 x40`也是一种并串行传送。

注：该CPU对于一个16bit数据，先拆成两组，每组8bit；8条数据通路并行传输8bit，随后再串行传输一次

##### 分时传送

分时传送有两种含义：

-   一是采用总线复用技术，在某个传输线上既传送地址信息，又传送数据信息，其目的是减少线缆数目，为此必须划分时间片，以便在不同的时段分别完成传送地 址和传送数据的任务；
-   二是指共享总线的部件分时使用总线，总线资源是系统的公共资源，挂在总线上的部件可以有很多，但同一个时刻总线使用权只能由一个主设备控制，当多个部件要求使用总线时，只能由总线控制器按时间片分时提供服务。

#### 8.2.2.2 数据传送模式

当前的总线标准大多能支持以下 4 类数据传送模式：

1.   **读、写操作**：读操作是由从设备到主设备的数据传送，而写操作是由主设备到从设备的数据传送。一般 情况下，主设备先以一个总线时钟周期发出命令和从设备地址，经过一定的延迟再开始数据传送。 为了提高总线利用率，减少延时损失，在分离事务通信中将总线传输过程分为两个阶段：第一个阶段主设备完成寻址阶段任务后让出总线控制权供其他主设备使用；从设备准备好数据后重新申请总线，完成第二个阶段的数据传送任务。
2.   **块传送操作**：只需给出数据块的起始地址，然后逐个地读出或写入数据块中的每一个字即可。这种方式 就是**突发传送模式**，其数据块长度一般固定为数据线宽度（存储器字长）的 4 倍。
3.   写后读、读修改写操作：只给出地址一次，就可完成先写后读或先读后写操作。**前者用于达到校验目的，后者用于在多个程序系统中对共享存储资源的保护。**这两种操作和突发模式的块传送一样，主设备控制总线直至整个操作完成。
4.   **广播、广集操作**：一般而言，数据传送只在一个主设备和一个从设备之间进行。但有的总线允许一个主设备对多个从设备进行写操作，这种操作称为**广播**。与广播相反的操作称为**广集**，它将选定的多个从设备数据在总线上完成逻辑与或逻辑或的操作，以检测多个中断源。

### 8.2.3 总线仲裁

总线仲裁也称总线控制、总线裁决 / 判优。

-   总线仲裁：对总线的使用进行合理的分配和管理。
    -   【现代计算机中总线上存在多个主设备，都能控制共享总线】
    -   【获得总线控制权的主设备称为**活动主设备**】活动主设备获得总线使用权后即可开始使用总线，进入寻址阶段和传输阶段；数据传输完毕后，进入总线结束阶段，结束阶段需要向**总线控制器**发送总线使用结束的信号，这样总线控制器就可以再次分配总线使用权。
    -   各个部件要使用总线进行通信时，需要向总线控制部件发请求信号
    -   总线控制部件按各部件的优先级来决定谁使用总线

-   根据总线控制部件的位置，仲裁方式分两类
    -   集中式总线仲裁
    -   分布式总线仲裁

#### 8.2.3.1 集中式仲裁

集中式仲裁包括链式查询、计数器定时查询及独立请求 3 种方式。

##### 1、链式查询方式

该方式又称为菊花链（Daisy）查询方式，总线仲裁需要 3 根控制线。

-   总线请求信号 BR（Bus Request）：用于向总线控制器传送总线使用申请信号，该信号有效时表示总线上至少有一个主设备请求使用总线。
-   总线许可信号 BG（Bus Grant）：总线控制器向设备发出的总线许可应答信号，该信号将各个设备像菊花链一样串行连接，菊花链因此得名；该信号有效时，表示总线控制器正在响应某个设备的总线请求。
-   总线忙信号 BS（Bus Busy）：BS=0 表示总线空闲，主设备获得总线使用许可后会立即将 BS 置为 1，表示总线正在使用中。

![image-20250619110706325](D:\universityResource\_课程\计算机组成原理_大一下\pic\链式查询方式（菊花型）.png)

>   [!NOTE]
>
>   <u>链式查询的**优点**是结构简单、控制线少、扩充容易；</u>
>
>   <u>缺点是各设备优先级固定，设备离总线控制器越近优先级越高，当优先级高的设备频繁请求使用总线时，会使优先级较低的设备长期不能使用总线，这种现象又称**饥饿现象**。</u>
>
>   -   采用链式查询方式，BG 信号每向后传递一次就需要一个时钟周期，<u>仲裁速度慢</u>。
>
>   -   另外链式查询方式还存在单点故障，一旦某个设备接口的链路出现故障，则该设备之后的所有设备都不能正常工作。

##### 2、计数器定时查询方式

计数器定时查询方式采用一个计数器控制总线使用权。

![image-20250619110839488](D:\universityResource\_课程\计算机组成原理_大一下\pic\计数器定时查询方式.png)

-   增加：设备地址计数线（$log_2 n$根）代替总线授权线BG
-   总线控制器：`if（BS==0 and BR==1）`,设备地址计数器开始计数，计数值通过地址计数线发向各个设备
-   请求总线的主设备：接口处的地址判别逻辑判断，`if（计数值==该设备的地址一致）`， BS线置1占用总线

>   [!NOTE]
>
>   -   优点：优先级可变化（通过设置地址计数器的初值）; 故障不敏感
>   -   缺点：响应慢；扩展困难
>   -   它同样一个时钟周期只能计数一次，所以<u>其响应速度和链式查询方式一样慢</u>。

##### 3、独立请求方式

![image-20250619112400203](D:\universityResource\_课程\计算机组成原理_大一下\pic\独立请求方式.png)

仲裁过程：

1.   主设备i：通过`Bri`向总线控制器独立发送请求信号，在总线控制器中排队
2.   总线控制器：按优先次序决定当前响应设备号j，通过其`BGj`发送授权信号

总线控制器可以按一定的优先次序决定响应哪个设备的总线请求，这里可以使用不同的算法。

-   独立请求方式的优先级策略最为灵活，既可以采用固定的优先级，也可以采用公平的循环菊花链算法，还可以采用 FIFO、LRU 等动态优先级算法；另外总线许可信号不再需要逐个地对设备进行串行查询，其属于并行仲裁，响应时间最快。
-   但独立请求方式的总线控制器最为复杂， 且所需控制线数最多，共需要 2n+1 根。由于控制总线信号线数目也是有限的，为平衡成本和性能，在一些总线中还使用了分组链式的仲裁方式。
-   总线仲裁时包括多个菊花链，每个菊花链具有一对独立的总线请求和许可信号，如摩托罗拉公司的 VME 总线。

---

|            | 链式查询方式     | 计数器定时查询               | 独立请求方式        |
| ---------- | ---------------- | ---------------------------- | ------------------- |
| 控制线     | BS、BR、BG 共3根 | BS、BR、$log_2 n$ 共 2+log₂n | n组（BR、BG）共2n根 |
| 响应速度   | 慢               | 慢                           | 快                  |
| 优先级     | 优先级固定       | 可作适当变化                 | 可作灵活的变化      |
| 故障敏感度 | 非常敏感         | 不敏感                       | 不敏感              |
| 扩展方式   | 容易             | 难                           | 容易                |

---

#### 8.2.3.2 分布式仲裁

【了解即可】

-   **自举分布式仲裁**：每个设备只有检测到比自己优先级高的设备没有总线请求时才能发总线使用请求信号。

    ![image-20250619113800319](D:\universityResource\_课程\计算机组成原理_大一下\pic\自举分散式仲裁.png)

-   **并行竞争仲裁**：请求主设备直接将仲裁号通过“线或”方式发送到共享的仲裁线上，所有请求主设备都将仲裁线上的仲裁号与自己进行逐位比较，如果比自己大，则在仲裁线上撤销自己的仲裁号，最后竞争获胜的设备获得总线控制权。

-   **冲突检测分散式仲裁**：每个部件独立地请求使用总线。请求总线时若检测到其他部件在使用总线，则等待；若无则置总线忙信号，并获得总线的使用权。使用过程中还要坚持监听总线以避免冲突。

### 8.2.4 总线定时

总线定时：通信双方如何获知传输开始和传输结束，通信双方如何配合？

-   同步方式：利用公共时钟对传输过程的每一步进行控制
    -   主设备读命令发出后，**等待固定时长后默认数据总线上数据有效，取走数据**
    -   一个总线周期进行一次完整的数据传送；一个周期结束另一个周期立即开始
    -   适合快速设备，传输距离短，取决于最慢设备性能，无法检验数据有效性
-   异步方式：利用应答信号对传输过程进行控制，控制复杂，适合慢速设备
    -   非互锁：主设备的请求信号经过t1时间自动撤销（不确定从设备是否收到） ，从设备的应答信号经过t2时间后自动撤销（不确定主设备是否 收到） ；一次握手
    -   半互锁：主设备的请求信号只能在收到从设备的应答信号之后才撤销（确定从设备收到），从设备的应答信号经过t2时间后自动撤销（不确 定主设备是否收到）；两次握手
    -   全互锁：主设备的请求信号只能在收到从设备的应答信号之后才撤销（确定从设备收到），从设备的应答信号只能在检测主设备的请求信号 撤销之后才能撤销（确定主设备收到）；三次握手
-   半同步方式：结合同步方式和异步方式的特点
    -   引入时钟信号，握手信号在时钟触发时被采样，解决异步方式的噪声敏感问题（异步中引入时钟
    -   引入等待信号wait：为1表示数据未准备好，请主设备等待；数据准备好并发送到总线上，wait信号置0，主设备取走数据（同步中引入应答）
-   分离事务通信方式：在从设备数据准备的过程中释放总线使用权；提高总线利用率，控制复杂；PCIe、SCSI总线
    -   从设备应答后，主设备释放总线控制权
    -   从设备准备数据时总线可处理其他总线事务
    -   从设备准备好数据后，主设备重新申请总线传输数据


>   [!NOTE]
>
>   【例8.4】假定某总线的时钟频率为1GHz，每次总线传输需要1个时钟周期， 总线的数据总线宽度为64位，存储器的存储周期为2个时钟周期，求同步方式下CPU从该存储器中读一个存储字时总线的数据传输率为多少？ 
>
>   解：
>
>   总线时钟周期 = 1/f =1/1GHz=1 ns 
>
>   则同步方式下存储器读操作步骤（计算请求阶段的时间不能确定，此处省略） 
>
>   1.   寻址阶段：CPU传送地址至存储器，需要一个总线周期时间，1ns; 
>
>   2.   存储器读数据并传输到数据总线：需要一个存储周期，2ns; 
>
>   3.   数据通过数据总线传送至CPU：需要一个总线周期1ns。 
>   
>   则同步方式下从主存读一个存储字的总时间（总线周期、总线传输周期）：T = 4ns 
>   数据传输率 = 8B / 4ns = 2 GB/s



## 8.3 总线结构

**总线结构**：总线排列及与其它各部件的连接方式。

主要类型有**单总线结构、双总线结构、三总线结构和高性能总线**

### 8.3.0 总线结构与系统性能关系

1.   最大存储容量：**单总线系统中内存要为外设保留一些地址**，存储容量最小
2.   指令系统：单总线系统中无须专门的I/O指令，**多总线系统中设有专门的I/O指令**
3.   吞吐量：**多总线系统比单总线系统要大得多**

### 8.3.1 单总线结构

在单总线结构的计算机中只有一条系统总线，CPU、DRAM、显卡、磁盘、键盘等所有部件和 I/O 设备都通过总线 I/O 接口连接在系统总线上，构成一个完整的计算机系统，此时系统总线连接所有功能部件，又可称为全局总线。局部总线就是相对这个概念而来的，单总线结构如图 8.22 所示。从 Intel 8088 到 80386 阶段的 ISA、EISA、MCA 总线都是典型的单总线结构。

![image-20250616163635528](D:\universityResource\_课程\计算机组成原理_大一下\pic\单总线结构.png)

-   总线结构简单，使用灵活，扩充容易
-   存储器与I/O设备统一编址，简化指令系统，存储空间减少
-   共享总线，分时使用，**通信速度慢**
-   **高速设备的高速特性得不到发挥**

### 8.3.2 双总线结构

#### 8.3.2.1 双总线结构-1-主存为中心

以主存为中心的双总线结构，为降低系统总线负载，提升 CPU 与主存（DRAM）之间的访问性能，额外增加了一条 CPU 与内存控制器之间的高速存储总线（也称**主存总线**），这里内存控制器为双端口存储控制器，同时连接存储总线与系统总线。
**CPU 通过存储总线访问主存，而访问外部设备则通过系统总线进行，外部设备与主存之间、CPU 和主存之间的数据传送可并行进行。**
需要注意的是这里的 CPU 实际上是 CPU 芯片与板载外部 cache 控制器的抽象，CPU 通过后端总线 BSB 与板载外部 cache 控制器相连，由 cache 控制器连接存储总线和系统总线。

![image-20250616164023564](D:\universityResource\_课程\计算机组成原理_大一下\pic\双总线结构1（主存中心）.png)

-   存储总线有效降低系统总线负载，提升了并行性
-   需增加专门的I/O指令，存储空间扩大
-   结构简单，系统扩展容易

#### 8.3.2.2 双总线结构-2-桥接器架构

该结构将计算机中的慢速设备从系统总线上分离到单独的 I/O 总线上，将 CPU、主存以及一些高速设备（显卡、SCSI、高速网卡等） 直接连接在局部总线（系统总线）上，而将慢速的 I/O 设备全部挂接在分离的 I/O 总线上。

I/O 总线与系统总线之间通过桥接器相连。

**桥接器是一种特殊的设备，用于连接两种不同的总线，本质上是扩展总线控制器**，用于在系统总线上扩展 I/O 总线。它既可以用于 I/O 总线仲裁，也可用于实现两种不同总线之间的操作转发。

![image-20250616164613026](D:\universityResource\_课程\计算机组成原理_大一下\pic\双总线结构2（桥接器）.png)

【图中ISA桥，桥接了I/O总线和系统总线】

>   [!NOTE]
>
>   两种不同的双总线结构采用了不同的思路，前者将 CPU 和主存之间的高速访问从系统总线中分离出来，后者则将慢速的外部设备通信从系统总线中分离出来，二者的基本思想都是将总线中的慢速活动与高速活动相分离。双总线结构相比单总线结构，吞吐能力更强，CPU 的工作效率较高，但都需要增加额外的硬件设备。

### 8.3.3 三总线结构

PCI 总线出现以后，个人计算机总线演变成三总线结构，分别是 **HOST 总线、PCI 总线、 ISA 总线**。

CPU、DRAM、PCI 桥连接在 HOST 总线（又称 CPU 总线、系统总线）上；HOST 总线通过 PCI 桥连接 PCI 总线，高速设备直接连接在 PCI 总线上。

为了提高 PCI 总线的负载能力，支持更多的 PCI 设备，图中增加了 PCI/PCI 桥来扩展 PCI 总线。

PCI 总线通过 PCI/ISA 桥与更慢速的 ISA 总线连接在一起，用于连接传统的慢速的串口、并口设备及 PS/2 鼠 标与键盘等，这里的 ISA 总线也称为遗留总线（Legacy Bus）。

![image-20250616165014236](D:\universityResource\_课程\计算机组成原理_大一下\pic\三总线结构.png)

这种结构进一步将不同速率的传输活动进行细分，将最快的 CPU、DRAM 放在系统总线上， 将显卡、磁盘、网卡等高速设备连接在 PCI 总线上，而将传统的慢速设备连接在 ISA 总线上， 使计算机系统性能进一步提升。

>   [!NOTE]
>
>   有些教科书上还介绍了主存总线、DMA 总线、I/O 总线组成的三总线结构，多见于专用的 CPU 结构。而个人计算机中并没有专门的 DMA 总线这种结构，设备与主存之间的 DMA 传输都是通过系统总线进行完成的。

### 8.3.4 高性能总线结构

随着计算机技术不断发展，CPU 性能不断提升，高速外部设备（如高速网络、高速视频图 形设备等）也不断涌现，**PCI 总线也逐渐遇到瓶颈**，**后续又诞生了 AGP 图形加速总线、PCIe 总线等**。

总线的结构也在不断变化，逐渐向高性能方向发展，其总体发展趋势包括以下几种：

1.   采用分层次的多总线结构，不同层次总线之间采用桥接方式连接和缓冲。
2.   将 I/O 设备与主存之间的通信与处理器的活动分离开来。
3.   高速设备靠近 CPU，慢速设备远离 CPU。
4.   桥接芯片高度集成，形成了**经典的南北桥架构**。

【结合往年真题应该不会考，复习建议看书】

---

【还有8.4 常用总线】【结合往年真题应该不会考，复习建议看书】

---

# chap9 输入输出系统

输入输出（I/O）系统主要用于实现 CPU 与外部设备、外部设备与主存之间的信息交换。

输入输出系统是典型的软、硬件协同系统，既包括 I/O 设备、I/O 接口、总线、I/O 管理部件等 I/O 硬件系 统，也包括驱动程序、软件访问接口、用户程序等 I/O 软件系统。

## 9.1 输入输出设备与特性

输入输出设备是计算机与人或者机器系统进行数据交互的装置，用于实现计算机内部二进制信息与外部不同形式信息的转换，简称外部设备或外设。输入输出设备特性：**异步性**、**实时性**、**独立性**。

外部设备、接口部件、总线以及相应的管理软件统称为计算机的输入/输出系统，简称I/O系统。

 I/O硬件：外设、控制器、I/O接口、总线

I/O软件：I/O库函数、驱动程序

I/O系统的功能：

1.   保证CPU能够正确选择I/O设备，并实现对其的控制与数据传输（找得到）
2.   完成计算机内部二进制信息与外部多种信息形式间的交流（听得懂）
3.   利用数据缓冲、合适的数据传送方式，实现主机外设间速度匹配（互相配合）

## 9.2 I/O接口 

一个计算机系统中包括多个 I/O 设备，所有设备均通过 I/O 接口（总线接口）与总线相连， CPU 使用设备地址经总线与 I/O 接口通信来访问 I/O 设备。I/O 接口是连接总线与 I/O 设备的物理和逻辑界面，既包括物理连接电路，也包括软件交互的逻辑接口。总线标准化直接使接口标准化，采用标准接口进行设备连接有利于增强输入输出系统的独立性，降低连接的复杂度。

### 9.2.1 I/O接口的功能

I/O接口的功能：设备寻址、设备控制、数据交互、数据缓冲、格式转换、状态检测。

-   **设备寻址**：接收来自总线的地址信息，经过译码电路，选择对应外部设备中的寄存器或存储器。计算机系统会对不同外部设备中的寄存器、存储器进行统一的端口地址或主存地址分配，不同外部设备，甚至同一外部设备中的不同寄存器的端口地址均不相同，因此对这些外部设备的访问可能需要根据访问的内容选择不同的地址。
-   **数据交互**：实现外部设备、主存与 CPU 之间的数据交换，这也是接口最基本的功能。
-   **设备控制**：传送 CPU 命令。接口能存储和识别 CPU 传送来的命令，并将命令传送到外部设备。这些命令主要有控制（启、停、复位等）、测试、读、写等。
-   **状态检测**：反映外部设备的工作状态。进行输入输出操作时，接口随时采集并保存外部设备的工作状况，以备 CPU 查询。这些状态有设备忙、设备就绪、设备故障、中断请求等。
-   **数据缓冲**：匹配 CPU 与外部设备的速度差距。CPU、主存传送信息的速度远高于外部设备，为消除速度差异，通常采用设置数据缓冲寄存器暂存数据的方式，方便 CPU 通过总线快速访问外部设备；也有些设备采用**先进先出**缓冲区方式。
-   **格式转换**：**实现数据格式转换或逻辑电平信号转换**。外部设备的数据位宽和总线不同时，需要进行并串或串并的转换；如果信号电平与总线规范不同，信息交换的过程中还必须进行电平转换。

除上述功能外，接口还应有中断、时序控制和数据检错、纠错等功能。

### 9.2.2 I/O接口的结构

外部设备通过 I/O 接口连接总线，早期设备均通过接口直接连接在系统总线上与 CPU、主存相连，现代计算机普遍采用分离的层次总线结构，将不同速度的设备连接在不同层次的 I/O 总线上，I/O 总线再通过扩展总线控制器、桥芯片或者通道处理器与 CPU 进行数据交互。 

![image-20250618041042142](D:\universityResource\_课程\计算机组成原理_大一下\pic\IO接口通用结构.png)

I/O 接口内部主要包括总线接口和内部接口两部分，如图 9.1 所示。连接总线的总线接口必须按总线标准进行设计，这部分逻辑为接口的标准部分。而连接设备的内部接口逻辑因设备而异，是非标准的。虽然不同类型的 I/O 接口的内部电路、控制方式、复杂性差异较大，<u>但一般 I/O 接口都应包括如下基本的功能部件</u>：

1.   数据缓冲寄存器（DBR）：用于缓冲数据，以匹配 CPU 与外部设备之间的速度差异。 CPU 执行输入操作时，DBR 存放从 I/O 设备读取的数据，该数据将被 CPU 通过总线读取并送入 CPU 寄存器中；执行输出操作时 DBR 暂存 CPU 送来的数据，该数据最终会被输出至具体外部 设备。
2.   设备状态寄存器（DSR）：用于反馈设备状态，常见的状态信息如设备忙、设备就绪、 设备错误等。在程序查询方式中，CPU 通过读取状态寄存器来判断设备的状态，以确定程序下一步进行什么操作。
3.   设备命令寄存器（DCR）：用于接收 CPU 发送的设备控制命令，如设备复位、设备识别、 读写控制等，不同设备所能支持的命令不同，简单设备甚至没有命令寄存器，如简单的键盘输入和字符终端输出设备。有时状态和命令寄存器是合二为一的。
4.   设备存储器：这部分并不是必需的，常用于设备自身的运算和处理，如显卡中的 显存。
5.   地址译码器：用于识别地址总线上的地址是否是当前 I/O 接口连接的外部设备。
6.   数据格式转换逻辑：进行串并或并串传送的转换。

<u>CPU 使用设备地址访问 I/O 接口中的寄存器、存储器，从而间接与外部设备进行数据交互，这些寄存器、存储器都有唯一的设备地址与之对应。</u>CPU 访问设备时会将设备地址加载在地址总线上，由接口内的地址译码逻辑识别当前地址是否访问当前接口。数据交互直接通过数据总线完成，注意命令 / 状态寄存器中的数据也是通过数据总线与 CPU 进行交互的，这意味着数据总线也是可以传输设备控制命令和状态信息的。控制总线用于传输总线控制命令和时序信号，主要用于负责总线控制权协商、应答以及中断响应。现代总线普遍支持总线主控技术， I/O 接口也可成为主设备来直接发起 DMA 请求以获得总线控制权，负责设备和内存之间的数据交互，因此 I/O 接口也可以向总线发送地址和控制命令信号，所以图 9.1 中 3 类总线均是双向传输的。

### 9.2.3 I/O接口编址

**所有 I/O 接口中的命令寄存器、状态寄存器、数据缓冲寄存器以及存储器都由 CPU 进行统一的设备地址分配，并通过对应的设备地址访问。**不同体系结构的 CPU 中的 I/O 编址方式不同， 通常可分为统一编址和独立编址两类。

#### 统一编址

也称内存映射编址（Memory-mapped），这种方式中外部设备地址与内存地址统一编址，二者在逻辑上处于同一个地址空间，通过不同的地址区域来区分是访问内存还是外部设备。

统一编址不需要设置专用的 I/O 指令，采用 Load/ Store 访存指令就可以访问外部设备，具体访问什么设备取决于地址。从汇编上看，访问I/O和标准内存是一致的：

```assembly
lbu $t0, 0x00010001 		#从内存读取一个字节送至寄存器$t0
lbu $t0, 0xffff0000 		#从I/O设备读取一个字节送至寄存器$t0
```

I/O 接口中的不同寄存器、存储器都会在统一地址空间中分配到一个唯一的地址与之对应，<u>通常计算机系统中大部分 I/O 接口的地址都是固定的</u>，在设计软、硬件时都需要遵循相应的约定； <u>而通过扩展卡扩展的设备以及热插拔设备的 I/O 地址则是在计算机启动过程中动态分配的</u>。

**需要注意 I/O 地址虽然映射到了主存空间中，使用访存指令进行访问，但由于接口中的数据是动态变化的，因此不能使用 cache 进行缓存，否则 CPU 无法了解设备状态的实时变化。**在 C 语言中接口数据变量应该声明为 volatile 型，表明该变量是会经常自动变化的，以防止出现不恰当的编译 优化。

统一编址的优势是编程更加灵活，无须专用的 I/O 指令，但主存空间由于被设备地址占用而减少。另外，外部设备地址和主存地址等长，所以接口中的译码逻辑相对复杂。

通常 MIPS、 ARM 等 RISC 处理器普遍采用这种方式。

#### 独立编码

也称端口映射编址（Port-mapped），这种方式中 I/O 地址空间与主存地址空间相互独立，I/O 地址空间不再占用主存地址空间，<u>此时 I/O 地址又称为 I/O 端口</u>。不同设备中的不同寄存器和存储器都有唯一的端口地址，必须使用特殊的 I/O 指令访问外部设备。

Intel x86 处理器普遍采用这种编址方式，如 80386 处理器的主存地址空间为 00000000 ～ FFFFFFFF，共 4GB；而 I/O 地址空间是 0000H ～ FFFFH，共 64KB；两部分地址区间是重叠的，用 MOV 指令访问内存，用 IN/OUT 指令访问外部设备。

不同指令会生成不同的总线控制信号来标识地址总线上的地址是主存还是 I/O 地址，如 ISA 总线中用 `MemR#`、`MemW#`、`IOR#`、`IOW#` 4 条信号线来区分。下面的代码是 x86 汇编语言访问 I/O 端口的实例。

```assembly
# x86

OUT   DX , AL 			#I/O写：将AL寄存器中存放的字节写入DX寄存器对应的I/O端口地址中
IN    AL , DX 			#I/O读：从DX寄存器对应的I/O端口地址读取一个字节送至AL寄存器
MOV  [BX], AL 		     #内存写：将AL寄存器中的值送到BX寄存器对应的内存单元中
```

在 x86 架构的个人计算机中，I/O 端口地址通常也是固定的，同样热插拔设备的端口地址也 是在启动过程中动态分配的。

---

**64KB 的 I/O 地址空间相对较小，地址译码逻辑简单，但随着外部设备中内置存储器空间的不断增大，如显卡中的显存空间，I/O 地址空间变成非常受限的资源，一旦 I/O 端口地址冲突就会引起设备异常。**

PCI 总线出现后，不论采用哪种编址方式，外部设备接口中的存储器都必须通过内存映射的方式【统一编码】映射到主存空间。

---

### 9.2.4 I/O 接口的软件

在现代计算机中，用户并不能直接访问设备，必须通过操作系统间接访问设备。

操作系统提供了多层次的 I/O 软件来支撑输入输出系统，可以有效屏蔽复杂的设备细节，使用户输入、输出更加方便。通常操作系统中的 I/O 软件主要包括如下3个层次：

![image-20250618043922528](D:\universityResource\_课程\计算机组成原理_大一下\pic\操作系统中的IO软件层次.png)

-   **与操作系统无关的I/O库 (用户态)** 
    -   用户程序主要通过调用I/O库访问设备，方便程序在不同OS间移植
    -   【对应语言函数】如C语言中的标准I/O库`stdio.h`，相关函数如`printf`、`scanf`、`getchar`、`putchar`、`fopen`、`fseek`、`fread`、`fwrite`、`fclose`等
-   **与设备无关的操作系统调用库（内核态）**
    -   屏蔽了设备的具体访问细节，向用户提供统一的I/O调用接口
    -   【对应操作系统函数】如UNIX操作系统中的函数`open`、`read`、`write`、`seek`、`ioctl`、`close`
    -   **用户程序可以直接调用系统调用库访问设备，但需要从用户态切换到内核态，产生较大开销；也不便于程序移植**
-   **独立的设备驱动程序（内核态）**
    -   设备驱动程序是与设备相关的I/O软件部分，**不同设备对应不同的驱动程序**
    -   遵循具体设备的I/O接口约定，包含设备接口细节
    -   设备驱动程序通过访问I/O接口中的数据缓冲寄存器DBR、命令寄存器DCR、状态寄存器DSR，与具体设备进行数据和命令交互。


### 9.2.5 I/O接口分类

I/O 接口可以从不同的角度进行分类。

1.   按数据传送方式可分为**并行接口**和**串行接口**。并行接口中多位数据并发传送，数据传送速度快但传输距离受限，如 SCSI、IDE 接口。串行接口中数据和控制信息是逐位传输的，主要用于串行外部设备或计算机的远程终端设备的连接。**相同频率下，串行接口的速度慢，但传送距离更长**，常见的如 SAS、SATA、USB 等。
2.   按接口的灵活性可分为**可编程接口**和**不可编程接口**。可编程接口常常具有多种不同的工作方式和功能，可根据实际需要，通过编程手段灵活选择。不可编程接口的功能固定。
3.   按通用性可分为**通用接口**和**专用接口**。通用接口可供多种外部设备使用，通用性强。如 USB 接口就可以连接可外接键盘、鼠标、磁盘、摄像头、打印机等不同类别的外部设备。专用接口是为某类外部设备或某种功能专门设计的，如 SATA 接口就只能用来连接存储设备。
4.   按总线传输的通信方式可分为**同步接口**和**异步接口**。同步接口与总线之间的信息传输由统一的时钟信号同步。异步接口与总线之间的信息传输采用应答方式控制。
5.   按访问外部设备的方式可分为**直接传送方式接口**、**程序控制方式接口**、**程序中断控制方式接口**、**DMA 接口**及**通道处理机接口**等。

## 9.3 数据传输控制方式

**CPU与外部设备之间的信息交换随外部设备性质的不同而采用不同的控制方式**。随着计算机技术的发展，控制方式也经历了由简单到复杂、由低效率到高效率、由 CPU 集中控制到各部件分散控制的发展过程，具体表现在下列几种传输控制方式中。

【按照要求，只需要知道下面四种控制方式】

 程序控制方式：1. 程序中断方式 ；2. 直接内存访问（DMA）方式 3. 通道方式；4. 外围处理机方式

### 9.3.1 程序控制方式

**程序控制方式是指输入输出完全依靠 CPU 执行程序实现**，当 CPU 要与设备进行数据交换时，首先设置接口命令寄存器启动设备；设备准备的过程中，CPU 通过读取接口中的状态寄存器查询设备是否已就绪，根据查询结果决定下一步操作究竟是进行数据传送还是等待。

-   这种控制方式的接口设计简单，但是CPU与外部设备只能串行工作，CPU会浪费大量的时间进行查询和等待，系统效率较低。

程序控制方式多见于早期单任务操作系统中，现代计算机在操作系统启动引导至多任务操作系统之前也采用这种方法与设备交互。

### 9.3.2 程序中断控制方式

程序中断控制方式中CPU启动外部设备后不再查询外部设备状态，而是将当前进程放入等待队列并转去执行其他进程，当外部设备准备好后主动向 CPU 发送中断请求。CPU 会在适当的时机响应中断请求，暂停正在执行的程序并调用相应的中断服务程序，由中断服务程序唤醒等待进程，完成 CPU 与外部设备之间的一次信息传输。中断服务程序执行完毕后，CPU 又返回被中断的程序继续执行。

这种 I/O 方式中，CPU 与外部设备可并行工作，CPU 利用率得到提高。

这种方式每传送一次数据就要发生一次中断，而中断服务存在现场保护、恢复的辅助开销，如每次中断只传输一个字节或机器字，辅助开销将远大于实际数据传输的 CPU 开销，传输效率十分低下，通常可以采用更大的数据块为单位进行传输来降低中断开销的影响。

### 9.3.3 直接内存访问方式DMA

程序控制和程序中断控制方式都需要 CPU 执行程序进行实际的数据传输，主要任务是将 I/O 接口中的数据送入 CPU 寄存器，再由寄存器送入内存，数据交换需要 CPU 寄存器进行中转。采用中断技术后，这部分开销成为 I/O 传输技术发展的主要瓶颈，由此出现了直接内存访问方式（Direct Memory Access，DMA）。

-   该方式由硬件（即 DMA 控制器，简称 DMAC）临时代替CPU控制总线，控制设备和内存之间进行直接的数据交换，信息传送不再经过 CPU 寄存器中转。 

-   它不但具有程序中断控制方式的优点，即在设备准备阶段，CPU 与外部设备能并行工作；还有效消除了数据实际传输过程中 CPU 的寄存器中转开销，大大提高了传输速率和 CPU 利用率。

### 9.3.4 通道方式

外部设备种类越来越多，数量也越来越多，因此对外部设备的管理与控制也就愈来愈复杂。 

除 DMA 数据传输外，I/O 设备还存在很多辅助的慢速操作，大多采用中断控制方式实现，这些操作都会影响 CPU 的效率。

-   为进一步减少 CPU 被 I/O 操作中断的次数，提高 CPU 效率，出现了通道技术，由通道分担 CPU 的 I/O 管理，能有效提高系统效率。

通道拥有独立的通道指令系统，可以通过执行通道程序来完成 CPU 指定的 I/O 任务，通道指令一般包含被交换数据在内存中的位置、传送方向、数据块长度，以及被控制的 I/O 设备的地 址信息、特征信息（如是磁带还是磁盘设备）等。当通道执行完相应通道程序后，会发出中断请求表示 I/O 管理结束，CPU 响应中断请求，执行相应的中断处理程序进行处理。

### 9.3.5 外围处理机方式

外围处理机（PPU）方式是通道方式的进一步发展，通常用于大中型计算机系统中。由于 PPU 基本上独立于 CPU 工作，其结构更接近一般处理机，甚至就是一般的通用微小型计算机。 它可以实现 I/O 处理器功能，还可以完成码制变换、格式处理及数据块检错、纠错等操作。

![image-20250618050932123](D:\universityResource\_课程\计算机组成原理_大一下\pic\IO控制方式.png)

## 9.4 程序控制方式【主要介绍程序查询】

程序控制方式（Programed I/O，PIO）是最原始、最简单的方式。

-   其基本思想是 CPU 直接执行一段输入输出程序来实现 CPU 与外部设备的数据交换。

程序控制方式又可细分为**程序查询**和**直接传送**两种。

1.   程序查询方式又称为轮询方式（Polling），程序查询方式每次传送前都要查询设备状态，只有当设备准备就绪后才可进行后续操作，因此其属于有条件传送方式。
2.   而直接传送方式是一种无条件传送方式，无须查询设备状态即可与设备进行数据交互，可以看作程序查询方式的特殊情况，通常适合非常简单的开关、LED 显示等设备。 

程序查询方式中输入输出程序主要通过与 I/O 接口中的命令寄存器 DCR、状态寄存器 DSR 和数据缓冲寄存器 DBR 进行数据交互来实现设备控制和传输。注意不同 I/O 接口中 DCR、 DSR、DBR 的寄存器位宽、数目及寄存器各位的功能定义均不相同，编写设备驱动程序时必须遵循厂商的约定。不同类型的设备，其程序查询的输入输出流程有所不同。

【主要介绍程序查询】

### 9.4.1 简单设备程序查询流程

【一般流程示例】

![image-20250618053535557](D:\universityResource\_课程\计算机组成原理_大一下\pic\简单设备查询流程.png)

#### 9.4.1.1 简单输入设备——键盘

以简单键盘输入设备为例，该设备没有命令寄存器，按键按下时键盘控制器会将键盘的键值 ASCII 数据存放在键盘数据缓冲寄存器 DBR 中，并同 时将状态寄存器 DSR 中对应的“数据就绪 Ready”位置为“1”，表示当前有按键数据。当 CPU 需要从键盘获取按键数据时，首先通过总线读取 DSR 寄存器，然后查询并判断 DSR 中的 Ready 位的状态，如果为“0”，则继续查询直至该位为“1”； 如果为“1”，则通过总线读取 DBR 中的按键编码，完成操作后 DSR 中的 Ready 位会自动归“0”。

---

【`deepseek`整理结果如下】

根据描述，键盘输入设备主要由以下两部分组成：

1.  数据缓冲寄存器 (DBR - Data Buffer Register)：用于存储按键的ASCII码值。当用户按下一个键时，键盘控制器会将对应的ASCII码放入这个寄存器。
2.  状态寄存器 (DSR - Data Status Register)：用于表示键盘的当前状态。特别地，它有一个“数据就绪”（Ready）位，用于指示DBR中是否有有效的数据。

CPU从键盘获取按键数据的过程如下：

1.  读取状态寄存器 (DSR)：CPU首先通过总线读取DSR的值。
2.  检查Ready位：
    -   如果Ready位为“0”：表示DBR中没有新的按键数据。CPU会继续查询DSR，直到Ready位变为“1”。
    -   如果Ready位为“1”：表示DBR中有有效的按键数据（即用户按下了某个键，且其ASCII码已存入DBR）。
3.  读取数据缓冲寄存器 (DBR)：当Ready位为“1”时，CPU通过总线读取DBR中的ASCII码。
4.  自动清除Ready位：在CPU读取DBR后，DSR中的Ready位会自动归“0”，表示DBR中的数据已被读取，可以准备接收新的按键数据。

---

-   具体访问流程如图 9.6（a）所示，如果需要获取多个按键，只需将这个流程加上循环控制即可。

#### 9.4.1.2 简单输出设备

而对于简单的字符终端输出设备，其程序查询方式也是类似的，当 CPU 需要输出字符到字符显示终端时，也是首先读取 DSR 的值，查询就绪位 Ready，如果 Ready 位为“1”，表示字符终端可以接收 CPU 的字符数据，此时 CPU 将字符数据写入 DBR 寄存器，字符终端接收到数据后会立即将 Ready 位复位为“0”，完成显示处理后才会重新将其置位为“1”，表示可以接收新的字符。如果为“0”，则表示设备还没有准备好，CPU 将继续查询 DSR 状态直至字符终端就绪。字符终端的具体访问流程如图 9.6（b）所示。同样，如果要连续输出多个字符，也需要将相应流程加上循环控制。

### 9.4.2 复杂设备程序查询流程

![image-20250618054055525](D:\universityResource\_课程\计算机组成原理_大一下\pic\复杂输入输出设备查询流程.png)

-   有些输入输出设备十分复杂，不能保持一直开启的状态，只需要在需要的时候启动即可。那么，在使用这类设备时，原本的直接读取数据阶段之前，就还需要加入一个设备启动控制阶段。

CPU 与复杂设备进行数据交互时，首先要查询设备的状态，只有设备就绪后，才可以通过总线向 I/O 接口发送命令与参数来启动设备，以明确告知设备要具体执行什么操作；设备收到命令后即刻去准备或处理，这个过程可能需要较长的时间，也就是常说的**设备准备阶段**。设备准备好后会将状态寄存器中相关位置位，表示命令执行完毕或准备就绪。而 CPU 在启动设备后就开始不断查询设备状态，当设备就绪时即可进行实际的数据传输，具体处理流程如图 9.7 所示。

第一次循环如果发现设备不正常，也可 以直接向设备发送复位命令。两次查询过程中查询的状态位有可能并不一样，具体取决于实际 的接口定义。

### 9.4.3 程序查询特点

程序查询方式中 CPU 通过直接执行输入输出程序与外部设备进行数据交换，对于简单设备则无须发送命令，当设备就绪后就可以直接进行数据传输；而复杂设备需要先发送设备命令和参数启动设备，让设备进入准备阶段，开始准备数据或处理工作。此时 CPU 要不断查询 I/O 接口中的状态寄存器 DSR，当设备就绪时才能进行下一操作，否则继续查询。

**通常将这种反复查询的过程称为轮询Polling**。

**对于字符设备，一次轮询只能传输一个字节或字，而块设备一次轮询可以传输一个数据块。**

轮询主要有两种策略，分别是忙等待（Busy-waiting）和定时轮询（Polling）。

-   轮询Polling具体分两种方式：
    -   忙等待（Busy-waiting），也称为独占式查询，当用户程序发出设备命令和参数后，CPU 开始地反复查询设备状态直至设备就绪，这个阶段 CPU 不能执行其他任务，称为忙等待状态。一旦设备就绪后 CPU 即可查询感知；然后开始进入实际数据传输阶段。这种方式中 CPU 浪费了大量的时间进行轮询操作。通常在单任务操作系统中可采用这种方式，此时 CPU 也不需要执行其他任务；另外对于超高速设备，由于设备响应快，这种方式也是可以接受的。 
        -   设备准备数据的时候CPU不能执行其他任务
        -   适合高速、简单设备
    -   定时轮询（Polling）：定时轮询不需要反复查询，CPU 启动设备后会启动一个定时中断；然后挂起当前用户进程 P1 并放入 I/O 等待队列，调度用户进程 P2 运行。定时时间到后 CPU 会执行定时中断服务程序， 该程序的主要作用是查询设备状态，如果设备准备好则唤醒等待进程 P1，否则将继续定时查询， 【如图 9.8（b）所示】。当然也可以直接唤醒 P1 进程让用户程序去查询，如果在独占查询循环体增加一个`sleep()` 函数，就可以实现这种模式。定时查询可以有效避免轮询等待 CPU 时间的浪费， 但其中断服务还是需要占用一定的 CPU 时间。定时轮询方式中 CPU 可以执行其他任务，有效节 约了 CPU 时间，适用于外部设备不支持中断的多任务操作系统。
        -   设备准备数据的时候CPU可以执行其他任务
-   传送数据方式分为两种：
    -  	字符设备：一次轮询传输一个字节或字
    -   块设备：一次轮询传输一个数据块
-  CPU与外设串行工作，反复查询设备状态占用较多CPU时间，系统效率低，用于早期的计算机

![image-20250618061351754](C:\Users\szl-d\AppData\Roaming\Typora\typora-user-images\不同程序查询方式的程序运行轨迹.png)

采用定时轮询后，定时时间间隔比较关键，如果过短，则用于定时查询的中断服务开销浪费较多；如果时间间隔过长，外部设备数据有可能得不到及时处理。合理地设置时间间隔，就可以保证外部设备的数据信息得到及时处理而不至于丢失数据，既提高了 CPU 利用率，又保证了输入输出的实时性。如键盘和鼠标的输入速度相对 CPU 来说是非常慢的，只要以比人反应速度快的频率定时轮询，就可以保证不丢失数据信息，其他设备也类似。

## 9.5 程序中断方式

由于 CPU 与外部设备速度相差巨大，设备数据准备阶段相对 CPU 来说是非常长的时间段，反复不停地查询设备状态会浪费大量的 CPU 时间，这是程序查询方式最大的问题。

为解决这个问题，产生了**程序中断控制Interrupt-driven I/O**的输入输出方式。

![image-20250618062103013](D:\universityResource\_课程\计算机组成原理_大一下\pic\程序查询与中断控制方式的程序运行轨迹对比.png)

>   [!NOTE]
>
>   【例 9.2】 某外部设备传送信息的最高频率为 40×103 次 / 秒，而相应的中断处理程序的执行时间为 40µs，问：该外部设备是否可以采用中断控制方式工作？为什么？ 
>
>   【解：】外部设备传送一次数据的时间 = 1/40×103 s = 25µs，即每次信息处理的时间都不能超过 25µs。由题目条件可知，采用中断控制方式执行一次 I/O 操作的时间最少是 40µs。因此，如果采用中断控制方式实现 I/O 将导致部分数据丢失，故不能采用中断控制方式，可以考虑使用程序查询方式。

相比独占式程序查询方式，中断控制方式不需要轮询设备状态。另外，设备主动请求中断的方式比定时查询方式更具有实时性，不需要考虑定时轮询频率的问题，可有效消除 CPU 轮询开销，大大提高了 I/O 效率，是现代计算机中普遍采用的一项重要技术。

但也需要注意，**中断控制方式也是有时间开销的**，相对程序查询方式，<u>它的额外开销是用于进程调度的两次上下文切换时间以及中断服务程序本身的开销</u>，其提高 I/O 效率的前提是这些额外开销小于设备准备时间，当设备准备数据时间较长的时候是没有问题的。但**对于极高速外部设备，设备准备数据的时间很短**，当这个时间比两次上下文切换加中断服务的开销还短时，使用中断控制方式的效率反而比忙等待轮询方式的效率更低，中断就会成为瓶颈**。所以程序查询方式并不一定只适合慢速设备，在一些高速设备中也被普遍采用**，例如最新的`NVMe SSD`硬盘在处理同步 I/O 时，就不再采用中断控制方式，而是采用程序查询方式进行数据交互。

### 程序中断方式特点

-   从设备的主动告知机制避免了CPU反复查询设备状态，提高了CPU的使用效率
    -   仍需占用CPU时间：中断服务子程序运行时间、中断开销（保存/恢复现场）
-   适合随机出现的服务
-   需要专门的硬件

### 9.5.1 中断的基本概念

<u>计算机系统运行时，若系统外部、内部或现行程序本身出现某种非预期的随机事件，CPU 将暂停现行程序的执行，**转向为该事件服务**；待事件处理完毕，再恢复执行原来被暂停的程序，这个过程称为中断。</u>产生非预期事件的原因很多，如除数为零、运算溢出、堆栈溢出、程序中断点、打印机缺纸、校验错、定时时间到、地址越界、虚存缺页等。这些中断事件对 CPU 来说大多都是随机发生的，CPU 不能预知这些事件发生的时刻；中断技术把有序的程序运行和无序的随机中断事件统一起来，大大增强了系统的处理能力和灵活性。

这样做可以**实现主机和外设准备阶段的并行工作，避免重复查询外设状态、提升工作效率。**

#### 1、中断的作用

中断技术赋于计算机应变能力，将有序的运行和无序的事件统一起来，大大增强了系统的处理能力

-   实现CPU和外设的并行工作
-   方便程序调试、故障处理
-   实时处理和人机交互：计算机在现场测试和控制、人机对话等应用中都具有很强的实时性，中断技术的主动告知特性能确保这些应用中的数据被及时处理。
-   多任务：进程时间片轮转必须借助定时中断技术实现中断。
-   多处理器交互：可以通过中断控制方式实现多处理器之间的信息交换和任务切换。

#### 2、中断的基本类型

【Page347/P334】【考点：内部异常与外部中断】

-   外部中断
    -   由CPU外部事件引起的中断，大部分由外设发出
    -   分为：**可屏蔽终端INTR**和**不可屏蔽中断NMI**
    -   这类中断事件往往与执行的程序无关，与程序的执行异步发生，且不具备可预测性和可重复性。因此， CPU 在每条指令执行结束后，会主动去检测外部设备是否在上一个指令周期发出过中断请求， 并根据检测的结果决定是否改变 CPU 的执行流程。
-   内部异常
    -   故障（Fault）：**由指令执行引起的异常**，如未定义指令、越权指令、段故障、缺页故障、存储保护违例、数据未对齐、除数为零、浮点溢出、整数溢出等。
    
        **分为：可恢复故障：指令需恢复执行；不可恢复故障：进程被终止**
    -   自陷（ trap）：一种事先安排的“异常”事件：通过在程序中显式的调用自陷指令触发自陷异常，例如MIPS中的SYSCALL
    -   终止（Abort）：随机出现的使得 CPU 无法继续执行的硬件故障，和具体指令无关，此时当前程序无法继续执行，只能终止执行，**由异常服务处理程序来重启系统**

#### 3、程序中断处理过程和辨析

![image-20250618070351323](D:\universityResource\_课程\计算机组成原理_大一下\pic\程序中断处理示意图.png)

>   [!NOTE]
>
>   QA：
>
>   Q：子程序与中断服务子程序与的区别？
>
>   A：子程序在特定位置显式调用，后者随机调用
>
>   Q：如果A，B，C同时产生中断？
>
>   A：中断**优先级问题**，中断仲裁
>
>   Q：如果正在运行A中断服务子程序，又收到B中断？
>
>   A：中断嵌套（多重中断）、**中断屏蔽**
>
>   Q：中断服务程序的入口地址如何获得？
>
>   A：向量中断和非向量中断

#### 4、中断优先级与中断屏蔽

中断优先级就是指 CPU **响应**并**处理**中断请求的先后次序。计算机系统中通常包括多个中断源，当同时有多个中断产生时，就存在中断优先级的问题，优先级高的先响应，优先级低的后响应。 多重中断中优先级高的中断请求可以中断 CPU 正在执行的低优先级中断服务程序。

**中断优先级包括两层含义：响应优先级和处理优先级。**

**响应优先级** 是指CPU对各设备中断请求进行响应的先后次序，其在硬件线路上是固定的，不便于变动。通常可以根据中断事件的重要性和迫切性来划分中断响应优先级，一般的划分规律如下：

1.   不可屏蔽中断 > 内部异常 > 可屏蔽中断。

2.   内部异常中硬件终止属于最高级，其次是指令异常或自陷等程序故障。

3.   DMA 中断请求优先于 I/O 设备传送的中断请求。

4.   在 I/O 传送类中断请求中，高速设备优先于低速设备，输入设备优先于输出设备，实时控制设备优先于普通设备。 

**处理优先级** 是指中断嵌套的实际优先级处理次序，通常可以利用中断屏蔽技术动态调整，从而使低优先级的中断也可以中断高优先级的中断服务程序，使中断处理更加灵活。<u>如果不使用**中断屏蔽技术**，处理优先级和响应优先级相同</u>。现代计算机中一般使用了中断屏蔽技术，在中断控制器中设置了中断屏蔽寄存器（Interrupt Mask Register，IMR）。IMR 中的每一位对应一个设备中断源，为“1”时表示屏蔽对应设备发送的中断请求信号，为“0”时表示允许发送，IMR 的值又称为**中断屏蔽字**，具体如图 9.12 所示。

#### 5、中断屏蔽字 IMR

【中断屏蔽字是重要技术】

![image-20250618073636281](D:\universityResource\_课程\计算机组成原理_大一下\pic\中断屏蔽字示意图.png)

【IMR 中的每一位对应一个设备中断源，<u>为“1”时表示屏蔽对应设备发送的中断请求信号</u>，为“0”时表示允许发送】

-   CPU 可以为每个设备分配不同的中断屏蔽字。

CPU 执行某设备的中断服务程序时，会将该设备的中断屏蔽字载入 IMR 中，所有中断请求信号都会与 IMR 中对应位的非值进行逻辑与，然后被送入中断优先级排队电路（优先编码器）进行优先级仲裁，如图 9.13 所示。被屏蔽的中断请求将无法传送到中断优先级排队电路，未被屏蔽的中断请求仍然通过中断优先级排 队电路按固定的响应优先级先后次序被处理。通过将高响应优先级的中断进行屏蔽的方式可以提升低优先级设备的处理优先级，避免低优先级的中断服务程序被高优先级的中断服务程序打断。【理解：响应优先级是默认顺序（硬件固定）】

![image-20250618074050402](D:\universityResource\_课程\计算机组成原理_大一下\pic\中断屏蔽技术原理.png)

-   中断屏蔽只对 CPU 运行中断服务程序时的中断嵌套有用，其并不能改变 CPU 运行主程序时的中断响应优先级。

**不可屏蔽中断不受中断屏蔽寄存器的控制**

#### 6、单级中断和多重中断

-   **单级中断**执行中断服务程序时不再响应其他中断请求。
-   而**多重中断**的中断服务程序可以被更高优先级的中断请求中断，多重中断也称**嵌套中断**。

注意二者都可以有多个中断源和中断优先级，区别在于多个中断之间能否嵌套。

![image-20250618073018798](D:\universityResource\_课程\计算机组成原理_大一下\pic\单级中断和多重中断的处理示意图.png)

图 9.11（a）所示的单级中断控制方式中只有在 1 号中断服务子程序完成并返回主程序后才能响应更高优先级的 0 号中断请求。而图 9.11（b）所示的多重中断中 1 号中断服务子程序在执行过程中被更高优先级的 0 号中断服务子程序再次打断， 先执行完成 0 号中断服务子程序后再返回来执行完 1 号中断服务子程序，最后返回主程序。对单级中断而言，先被 CPU 响应的中断服务程序先完成；对多重中断而言，先被 CPU 响应的中断服务程序不一定先完成。

-   中断屏蔽技术通过设置设备的中断屏蔽字动态调整处理优先级，可以实现低优先级中断打断高优先级中断服务
-   中断服务程序保护现场后开中断即可实现中断嵌套

### 9.5.2 中断请求【不要求】

【虽然不要求，但也是后面一部分的基础】

### 9.5.3 中断响应 

实现了中断请求的基本逻辑后，下一步就是实现 CPU 响应中断请求了。

#### 1、中断的响应条件

根据前面的硬件分析可知，CPU 响应某个外部设备中断请求需要满足一定的条件，这些条件包括以下几点。

1.   对应的中断请求未被屏蔽。
2.   当前没有更高优先级的其他中断请求。
3.   如果 CPU 正在执行中断服务，则中断请求应符合嵌套条件。
4.   中断使能位处于使能状态，也就是开中断状态，内部异常和不可屏蔽中断不受此限制。
5.   CPU 已执行完一条指令的最后一个状态周期（中断时机）。内部异常指令无法执行完毕，所以其中断时机不受此项制约。

#### 2、中断响应过程

CPU 一旦响应中断，就进入中断响应阶段，在这个时间段内，CPU 要完成下列工作。

1.   **关中断**：即临时禁止中断请求，主要是为了**保证保存断点和后续保护现场操作的完整性**，只有这样才能使中断服务程序完成后正确返回断点继续执行。

     注意开、关中断可以通过指令实现，也可以通过硬件自动实现，中断响应阶段的关中断操作是通过硬件自动完成的。

     【**设置中断允许触发器IE/IF =0**】

2.   **保存断点**：<u>即将程序计数器 PC 和处理器的状态寄存器 PSW 的内容压入堆栈或放入特定的单元保存</u>，x86 中需要保存 CS、IP、PSW 寄存器至内存堆栈中；而 MIPS 中没有状态寄存器， 只需要保存 PC 至 EPC 寄存器中。

     【注意：**内部异常和外部中断的断点有差异**】，内部异常指令并没有执行成功，异常处理后要重新执行，所以其断点是当前指令的地址。而外部中断的断点则是下一条指令的地址，如果指令顺序执行，断点是顺序指令地址，否则将是分支目标地址。

3.   **中断识别**：通<u>过硬件或软件方法查找中断源，清除当前中断请求，将对应的中断服务程序入口地址送入程序计数器 PC</u>，完成中断识别后即可正式执行中断服务程序。 上述 3 个任务可能需要 0 ～ n 个时钟周期才能完成，由于中断响应过程中 CPU 不能执行其他任务，因此中断响应的过程可以看作由 CPU 执行中断隐指令完成的，需要占用 CPU 时间。【注意中断隐指令并不存在，只是一种虚拟的说法，本质上就是硬件的一系列自动操作。】

### 9.5.4 中断识别

中断识别的任务是确定中断是由哪个中断源发出的，识别出中断源后还需要获取中断服务程序入口地址，这样才能执行中断服务程序。关于<u>中断源的识别在前面介绍中断请求信号传送的</u>时候已经进行了介绍，如果采用独立请求传送方式则采用硬件编码电路进行识别，也称为独立请求法；如果采用链式查询方式，可以采用硬件串行查询法和软件查询法，这里不再详述。

中断识别分为非向量中断和向量中断两种，其中，也可以说非向量中断并不需要进行中断识别【主要通过软件、程序实现】。本小节主要讨论较为常见的【向量中断——硬件查询法】。

【**响应时将中断号作为索引，查询中断向量表取得服务程序入口，转入相应服务程序。**】

#### 1、中断号

<u>在向量中断中每一个设备的中断源都有一个唯一的中断编号与之对应，称为中断号。</u>中断号在中断处理过程中起到很重要的作用，方便中断的识别和处理，CPU 可以通过中断号快速查找中断服务程序的入口地址，实现程序的转移。中断号由计算机系统统一分配，**通常是固定不变的**。

####  2、中断向量

中断向量：中断服务程序入口地址和程序状态字。形式是：

```
中断号A+入口AA
```

#### 3、中断向量表

中断向量表：中断向量的集合 。

### 9.5.5 中断处理

完成中断隐指令的执行后，CPU 就正式开始执行中断服务程序。

![image-20250618091006567](D:\universityResource\_课程\计算机组成原理_大一下\pic\中断处理流程图.png)

#### 中断服务程序与子函数的差异

| 差异点           | 中断服务程序                                     | 子函数                           |
| ---------------- | ------------------------------------------------ | -------------------------------- |
| 调用方式         | 随机调用                                         | 显示调用                         |
| 入口地址         | 由中断识别给出                                   | 由指令给出                       |
| 修改PC的方式     | 由中断隐指令完成                                 | 子函数调用指令负责               |
| 现场的内容       | 包含更多寄存器：所有会被中断服务程序改写的寄存器 | 只需保存可能被子函数改写的寄存器 |
| 返回主程序的方式 | 中断返回指令                                     | 函数返回指令                     |

注：中断隐指令：实际不存在中断隐指令，是在中断周期中硬件自动处理的操作

## 9.6 DMA 方式

直接内存访问（Direct Memory Access，DMA）就是为了减少 I/O 过程中 CPU 用于实际传输的开销而引入的。该方式在总线上设置了 DMA 控制器电路（DMAC），由 DMAC 临时接管总线代替 CPU 控制外部设备和内存之间的批量数据交换；CPU 不再参与实际数据传输过程，数据直接通过系统总线在外部设备和内存之间进行交换，完全消除了程序查询和程序中断控制方式中 CPU 进行实际数据传输的开销，系统效率得到了巨大提高。

### 9.6.1 DMA基本概念

-   中断方式：传送一个数据执行一次中断服务子程序（几十条指令），效率低下，不适合于高速传输的系统。

-   DMA方式：
    -   外设与主存间建立一个由硬件管理的数据通路（不一定有单独的通路）
    -   CPU不介入外设与主存的数据传送操作，减少CPU开销，提升效率
    -   DMA 方式中由 DMA 控制器暂时接管总线控制外部设备与内存之间的直接数据交换，**数据无须由 CPU 寄存器中转**。

![image-20250618095146936](D:\universityResource\_课程\计算机组成原理_大一下\pic\MDA概念.png)

DMA方式主要用于高速设备的块数据传输，常见的磁盘、显卡、网卡、声卡均支持DMA访问，这类设备的数据传输多采用数据块方式。DMA 甚至还可以用于内存数据的内部搬移，这种操作经常发生。如果利用 CPU 程序进行大批量的内存数据搬移，需要经过寄存器中转，会消耗大量的 CPU 资源，采用 DMA 方式则可以大大提高搬移效率。 DMA 方式是程序中断传送技术的进一步发展，在传输结束阶段复用了中断技术，它在硬件逻辑机构的支持下，以更快的速度、更简便的形式传送数据，和中断技术存在如下明显的区别：

-   二者均采用了“请求 - 应答”机制，但中断技术中请求的是 CPU 时间，响应的时机是指令周期结束时刻；

    **DMA 方式请求的是总线控制权**，响应时机是任何一个机器周期结束的时刻。

-   中断技术中通过 CPU 执行程序进行实际数据传送，存在程序执行现场的保护和恢复问题；而 DMA 方式依靠额外硬件来实现数据传输，其不改变 CPU 现场，不影响系统性能。

-   **DMA 方式仅仅用于数据的传输；而中断技术还可以用于处理各种随机事件，提高计算机的灵活性。**

### 9.6.2 内存争用问题

DMA 控制的关键是 DMAC 接管总线控制权，外部设备与主存交换数据时，CPU 仍可执行主程序。虽然大多时候 CPU 执行程序需要的指令和数据都可以在 cache 中获取，但还是可能**存在 DMAC 与 CPU 争用主存的问题**。为避免由此而引起的内存访问冲突，可以采用 DRAM 刷新控制器或与 CPU 的内存争用一样的解决方法，常用的方式有：

1.   停止 CPU 访问内存

2.   DMAC 与 CPU 交替访问内存

3.   周期挪用 3 种

图 9.21 所示为这 3 种方式的时间图。

![image-20250618100008476](D:\universityResource\_课程\计算机组成原理_大一下\pic\DMA传送方式_内存争用.png)

#### 1、停止 CPU 访问内存

即当外部设备使用 DMA 方式传送数据时，由 DMAC 向 CPU 发出接管系统总线的请求，CPU 在当前指令执行完毕后响应该请求，并将系统总线控制权交给 DMAC。DMAC 获得总线控制权以后，连续占用若干个总线周期进行数据传送。在一批数据传送完毕后，DMAC 通知 CPU 可以使用内存，并把总线控制权交还给 CPU，在整个 DMA 传送过程中，停止 CPU 对内存的访问。

-   优点是控制简单；

-   缺点是 CPU 可能较长时间不能访问内存，由于外部设备与内存速度差异较大，相当一部分内存的工作周期可能会被浪费，内存的效率不能被充分发挥。如软盘读一个字节约要 32µs，而 RAM 的存取周期为 1µs 左右，因此，在通过 DMA 方式从软盘读取一个字节的过程中，内存将有 31 个存储周期空闲。

#### 2、DMAC 与 CPU 交替访问内存

该方式将内存的存取周期分成两段，一段专用于 DMAC 访问内存，另一段专用于 CPU 访问内存；时间上不会发生冲突，可使 DMA 传送方式和 CPU 同时发挥最高的效率。

-   这种方式不需要总线使用权的申请、建立和交还等过程，总线使用权是分时控制的；
-   但这种方法会增加内存存储周期，且由于 CPU 及外部设备的速度与内存不匹配，因此可能有多个供 DMA 使用的内存时间片被浪费。

#### 3、周期挪用

周期挪用方式下，只有当 DMAC 需要访问内存时，CPU 才暂停一个存储周期供 DMAC 访问主存，一个数据（字或机器字）传送结束后，总线控制权被交还给 CPU，这种技术也称周期窃取（Cycle Stealing）。

-   周期挪用可能发生在指令周期下任何一个机器周期的结束时刻，DMA 操作期间不会修改CPU 寄存器，所以**没有现场保护的问题**。如果挪用周期期间 CPU 并不访问内存，则这种方式对 CPU 的执行没有性能影响；如果挪用周期期间 CPU 刚好也要访问内存，即形成访存冲突，此时， DMA 优先访问内存。

**周期挪用法已成为 DMA 传送方式的主要方法。**

### 9.6.3 DMA控制器基本结构

![image-20250618101139367](D:\universityResource\_课程\计算机组成原理_大一下\pic\DMA 控制器基本结构.png)

DMA 控制器的基本结构如图 9.22 所示，内部主要包括各类寄存器、DMA 控制逻辑等，其 各部分的作用分别如下：

1.   **地址计数器**。它用于<u>存放交换数据的内存地址</u>。<u>在 DMA 预处理阶段由 CPU 设置，每次 DMA 传送后自动递增，指向下一个内存单元</u>。
2.   **字计数器**。它用于<u>记录数据块的长度，也在预处理阶段设置</u>。传送开始后，每传送 1 个字或字节就**自动减 1**。当计数值为 0 时，数据传送完毕，发出 DMA 中断请求信号。
3.   **数据缓冲寄存器（DBR）**。DMAC 作为从设备时其可用来接收 CPU 传输的数据， DMAC 作为主设备时其可以用来暂存传输数据。当然，若不经过该寄存器直接通过数据总线实现设备和内存之间的数据交换，则性能更好。
4.   **命令寄存器（DCR）**。它用于接收 CPU 的控制命令。
5.   **状态寄存器（DSR）**。它负责向 CPU 反馈 DMA 控制器状态。
6.   **DMA 控制逻辑**。它包括控制和时序电路，以及状态标志，用来修改内存地址计数器和字计数器，指定数据传输方向，并对 DMA 请求信号和 CPU 响应信号进行协调和同步；控制逻辑还应该支持中断机制，一组数据交换完毕时，向 CPU 发出 DMA 中断请求，通知 CPU 进行结束处理。

>   [!NOTE]
>
>   注意在系统总线上有可能有多个 DMAC。在现代个人计算机中，CPU、DMAC、I/O 接口、内存均通过系统总线相连，并不存在所谓的专用数据通路连接设备和内存。

### 9.6.4 DMA 传输流程

![image-20250618101738198](D:\universityResource\_课程\计算机组成原理_大一下\pic\DMA 读操作详细流程（周期挪用）.png)

1.   准备阶段（预处理阶段）：
     1.   在CPU干预下，CPU向DMA接口发送必要的传送参数，如内存地址、数据块长度、数据传输方向...
     2.   启动I/O设备：CPU向I/O接口发送读写命令、相关参数有：设备地址、传输块大小、传输方向...
     3.   挂起当前进程，转向其它进程，以充分利用CPU资源

2.   传送阶段：CPU不参与，DMA连续传送一批数据

3.   结束阶段：CPU干预
     1.   DMA向主机发出中断请求
     2.   DMA在两种情况下都进入结束阶段：正常结束，一批数据传送完毕；非正常结束，DMA故障

## DMA与程序中断的区别

- 中断通过程序传送数据；DMA靠硬件来实现。
- 中断时机为两指令之间（指令周期）；DMA响应时机为两存储周期之间（机器周期）。
- 中断不仅具有数据传送能力，还能处理异常事件；DMA只能进行数据传送。
- DMA仅挪用了一个存储周期，不改变CPU现场。
- DMA请求的优先权比中断请求高
  - CPU优先响应DMA请求，是为了避免DMA所连接的高速外设丢失数据。
- DMA利用了中断技术（结束阶段）

---







